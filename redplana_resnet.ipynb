{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aaXODrEa_YEF"
   },
   "source": [
    "# Proyecto - Estudio del efecto de la profundidad y conexiones residuales en redes neuronales\n",
    "### EL4106 Inteligencia Computacional\n",
    "\n",
    "Profesor de Cátedra: Pablo Estévez<br>\n",
    "Profesor Auxiliar: Pablo Cornejo<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_kDCajXe_iQo"
   },
   "source": [
    "### Tema: Regularización\n",
    "La **regularización** es un conjunto de técnicas utilizadas en machine learning y deep learning para prevenir el **sobreajuste** (overfitting). El sobreajuste ocurre cuando un modelo aprende demasiado bien los detalles y ruido de los datos de entrenamiento, lo que resulta en un mal rendimiento cuando se evalúa en nuevos datos no vistos (conjunto de validación o test). La regularización ayuda a mejorar la **capacidad de generalización** del modelo, es decir, su capacidad para funcionar bien en datos no vistos.\n",
    "\n",
    "### Tipos comunes de regularización:\n",
    "\n",
    "1. **L2 Regularization (Weight Decay)**:\n",
    "   - **Descripción**: Penaliza los pesos grandes al agregar un término a la función de pérdida que aumenta con el tamaño de los pesos.\n",
    "   - **Fórmula**: El término de penalización en la función de pérdida es:\n",
    "$ L(\\theta) = L_0 + \\lambda \\sum_{i=1}^{n} \\theta_i^2 $\n",
    "     Donde:\n",
    "     - $ L_0 $ es la pérdida original (por ejemplo, la entropía cruzada).\n",
    "     - $ \\theta_i $ son los pesos de la red.\n",
    "     - $ \\lambda $ es el hiperparámetro que controla la magnitud de la penalización (también llamado **weight decay**).\n",
    "   - **Efecto**: Evita que los pesos crezcan demasiado, lo que podría hacer que el modelo sea demasiado dependiente de características particulares de los datos de entrenamiento.\n",
    "\n",
    "2. **L1 Regularization**:\n",
    "   - **Descripción**: Similar a L2, pero en lugar de penalizar los pesos grandes con un término cuadrático, penaliza la suma de los valores absolutos de los pesos.\n",
    "   - **Fórmula**:\n",
    "     $$\n",
    "  L(\\theta) = L_0 + \\lambda \\sum_{i=1}^{n} |\\theta_i|\n",
    "     $$\n",
    "   - **Efecto**: Alienta la **sparsity** (la mayoría de los pesos se vuelven cero), lo que puede resultar en modelos más simples.\n",
    "\n",
    "3. **Dropout**:\n",
    "   - **Descripción**: Durante el entrenamiento, **desactiva aleatoriamente** una fracción de las neuronas en cada capa en cada paso de entrenamiento. Esto evita que el modelo se vuelva demasiado dependiente de cualquier neurona individual.\n",
    "   - **Efecto**: Dropout actúa como un ensamble implícito de varias redes neuronales, entrenando diferentes subredes.\n",
    "\n",
    "4. **Early Stopping**:\n",
    "   - **Descripción**: Se detiene el entrenamiento del modelo cuando la precisión en el conjunto de validación deja de mejorar después de un cierto número de épocas.\n",
    "   - **Efecto**: Evita que el modelo continúe ajustándose demasiado a los datos de entrenamiento.\n",
    "\n",
    "5. **Data Augmentation**:\n",
    "   - **Descripción**: **Aumentar artificialmente** el conjunto de datos al aplicar transformaciones aleatorias (rotaciones, escalado, recortes, etc.) puede hacer que el modelo vea más variedad en los datos y evitar el sobreajuste.\n",
    "   - **Efecto**: Hace que el modelo aprenda características más generales y robustas.\n",
    "\n",
    "6. **Batch Normalization**:\n",
    "   - **Descripción**: Normaliza las activaciones de cada capa durante el entrenamiento, asegurando que la distribución de las activaciones permanezca estable. También tiene un efecto regularizador.\n",
    "   - **Efecto**: Ayuda a estabilizar y acelerar el entrenamiento, además de reducir el sobreajuste.\n",
    "\n",
    "### Aspectos a considerar al aplicar regularización:\n",
    "\n",
    "1. **Hiperparámetros**:\n",
    "   - El valor del coeficiente de regularización $\\lambda$ en L2/L1 es crucial. Si es muy bajo, no se sentirá el efecto de la regularización, y si es muy alto, puede hacer que el modelo sea demasiado conservador.\n",
    "   - Para **dropout**, la probabilidad de \"dropout\" $p$ debe seleccionarse cuidadosamente (valores comunes entre **0.3 y 0.5**).\n",
    "\n",
    "2. **Balance entre regularización y ajuste**:\n",
    "   - La regularización busca reducir el sobreajuste, pero demasiada regularización puede causar subajuste. Es importante encontrar un equilibrio.\n",
    "\n",
    "3. **Evaluación con conjunto de validación**:\n",
    "   - Siempre evalúa el impacto de la regularización en un conjunto de validación. Si la precisión de entrenamiento es alta pero la de validación es baja, probablemente estés sobreajustando.\n",
    "\n",
    "4. **Tamaño del modelo y datos**:\n",
    "   - Modelos grandes entrenados en conjuntos de datos pequeños son más propensos al sobreajuste, por lo que necesitan más regularización.\n",
    "\n",
    "### Ejemplo práctico:\n",
    "\n",
    "Si se está entrenando una red neuronal profunda en CIFAR-10 y se nota que el modelo tiene una alta precisión en el conjunto de entrenamiento pero baja en validación, es posible que esté ocurriendo sobreajuste. Por esto, se podria intentar:\n",
    "- Agregar **L2 regularization** al optimizador ajustando el parámetro `weight_decay` (por ejemplo, **1e-4**).\n",
    "- Aumentar el tamaño del conjunto de datos mediante **data augmentation** aplicando rotaciones, traslaciones o recortes aleatorios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gJzYbF7omap8",
    "outputId": "ab7a5871-dcde-4c80-9d51-c4008fccb07b"
   },
   "outputs": [],
   "source": [
    "!pip install umap-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "78iehVz9mcbF"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import umap.umap_ as umap\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from sklearn.manifold import TSNE\n",
    "from torch import Tensor\n",
    "from typing import Type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FYvNtSrnmdTc",
    "outputId": "dad7187d-2d72-448d-b2e8-ec9c9ea66205"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o5O-aFZg3cWQ"
   },
   "source": [
    "## Carga Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4V9bQLI43epY",
    "outputId": "17b71e1f-d810-48ab-d301-f36ff52e7239"
   },
   "outputs": [],
   "source": [
    "# Transformaciones para entrenamiento y validación\n",
    "train_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomCrop(32, padding=4),  # Recorte aleatorio después del padding\n",
    "    torchvision.transforms.RandomHorizontalFlip(),      # Volteo horizontal aleatorio\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)),\n",
    "])\n",
    "\n",
    "val_test_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)),\n",
    "])\n",
    "\n",
    "# Cargar datasets CIFAR-10 con transformaciones\n",
    "train_cifar10 = torchvision.datasets.CIFAR10(\n",
    "    root=\"./cifar10\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=train_transform  # Se aplica data augmentation aquí\n",
    ")\n",
    "\n",
    "test_cifar10 = torchvision.datasets.CIFAR10(\n",
    "    root=\"./cifar10\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=val_test_transform  # Solo normalización para testing\n",
    ")\n",
    "\n",
    "# Dividir dataset de entrenamiento y validación\n",
    "train_cifar10, _ = torch.utils.data.random_split(train_cifar10, [45000, 5000], generator=torch.Generator().manual_seed(42))\n",
    "_, val_cifar10 = torch.utils.data.random_split(\n",
    "    torchvision.datasets.CIFAR10(root=\"./cifar10\", train=True, transform=val_test_transform),\n",
    "    [45000, 5000], generator=torch.Generator().manual_seed(42)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X8dfIZsLmyE3"
   },
   "source": [
    "## Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cn9e6XUSnucW"
   },
   "source": [
    "### RedPlana20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oBmkYHIwnvvj",
    "outputId": "7bf53abf-5456-4e4a-d1f2-c45ebf0ab5ef"
   },
   "outputs": [],
   "source": [
    "# Definición de un bloque básico de la red plana (simple convolución + BN + ReLU)\n",
    "class PlainBlock(nn.Module):\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(PlainBlock, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(planes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn(self.conv(x)))\n",
    "        return out\n",
    "\n",
    "# Definición de la red plana con 20 capas convolucionales\n",
    "class PlainNet20(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(PlainNet20, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        # Capa de convolución inicial (1 capa)\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "\n",
    "        # 20 capas en total, distribuidas en 3 layers\n",
    "        self.layer1 = self._make_layer(64, 6, stride=1)   # 6 capas convolucionales (32x32)\n",
    "        self.layer2 = self._make_layer(128, 7, stride=2)  # 7 capas convolucionales (16x16)\n",
    "        self.layer3 = self._make_layer(256, 6, stride=2)  # 6 capas convolucionales (8x8)\n",
    "\n",
    "        # Pooling global\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "        # Capa completamente conectada\n",
    "        self.fc = nn.Linear(256, num_classes)\n",
    "\n",
    "    # Crear capas usando bloques básicos\n",
    "    def _make_layer(self, planes, num_blocks, stride):\n",
    "        layers = []\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        for s in strides:\n",
    "            layers.append(PlainBlock(self.in_planes, planes, stride=s))\n",
    "            self.in_planes = planes\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        feature_maps['ReLUconv1'] = out\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        feature_maps['Layer2'] = out\n",
    "        out = self.layer3(out)\n",
    "        feature_maps['Layer3'] = out\n",
    "        out = self.avgpool(out)\n",
    "        out = torch.flatten(out, 1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "# Crear el modelo\n",
    "model = PlainNet20(num_classes=10)\n",
    "\n",
    "# Imprimir la arquitectura\n",
    "print(model)\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mVMI4pGbm5Tf"
   },
   "source": [
    "### RedPlana32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jxZ178sKmzon",
    "outputId": "92927fb2-eb1d-41ea-9112-7f8b9789d9d4"
   },
   "outputs": [],
   "source": [
    "# Definición de un bloque básico de la red plana (simple convolución + BN + ReLU)\n",
    "class PlainBlock(nn.Module):\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(PlainBlock, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(planes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn(self.conv(x)))\n",
    "        return out\n",
    "\n",
    "# Definición de la red plana con 32 capas convolucionales\n",
    "class PlainNet32(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(PlainNet32, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        # Capa de convolución inicial\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "\n",
    "        # 32 capas de convoluciones simples (sin conexiones residuales)\n",
    "        self.layer1 = self._make_layer(64, 5, stride=1)   # 5 bloques (32x32)\n",
    "        self.layer2 = self._make_layer(128, 5, stride=2)  # 5 bloques (16x16)\n",
    "        self.layer3 = self._make_layer(256, 11, stride=2) # 11 bloques (8x8)\n",
    "        self.layer4 = self._make_layer(512, 11, stride=2) # 11 bloques (4x4)\n",
    "\n",
    "        # Pooling global\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "        # Capa completamente conectada\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    # Crear capas usando bloques básicos\n",
    "    def _make_layer(self, planes, num_blocks, stride):\n",
    "        layers = []\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        for s in strides:\n",
    "            layers.append(PlainBlock(self.in_planes, planes, stride=s))\n",
    "            self.in_planes = planes\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        feature_maps['ReLUconv1'] = out\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        feature_maps['Layer2'] = out\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        feature_maps['Layer4'] = out\n",
    "        out = self.avgpool(out)\n",
    "        out = torch.flatten(out, 1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "# Crear el modelo\n",
    "model = PlainNet32(num_classes=10)\n",
    "\n",
    "# Imprimir la arquitectura\n",
    "print(model)\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TwPsDYMQ0U-n"
   },
   "source": [
    "### ResNet20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-crTHnzG0W4G",
    "outputId": "a896b257-95ab-4813-f4fc-bc26ceafc0d3"
   },
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        # Shortcut connection\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion * planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion * planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))  # Apply BN and then ReLU\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)  # Apply shortcut connection\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet20(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet20, self).__init__()\n",
    "        self.in_planes = 16  # Following CIFAR-10 architecture, we start with 16 filters\n",
    "\n",
    "        # Initial convolutional layer (3x3 convolutions, per the description)\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # Residual layers\n",
    "        self.layer1 = self._make_layer(block, 16, num_blocks[0], stride=1)  # For 32x32 feature maps\n",
    "        self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2)  # For 16x16 feature maps\n",
    "        self.layer3 = self._make_layer(block, 64, num_blocks[2], stride=2)  # For 8x8 feature maps\n",
    "\n",
    "        # Global average pooling and fully connected layer\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.linear = nn.Linear(64 * block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)  # Apply stride to the first block\n",
    "        layers = []\n",
    "        for s in strides:\n",
    "            layers.append(block(self.in_planes, planes, s))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initial convolution\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        feature_maps['ReLUconv1'] = out\n",
    "        # Residual layers\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        feature_maps['Layer2'] = out\n",
    "        out = self.layer3(out)\n",
    "        feature_maps['Layer3'] = out\n",
    "\n",
    "        # Global average pooling\n",
    "        out = self.avgpool(out)\n",
    "        out = torch.flatten(out, 1)\n",
    "\n",
    "        # Fully connected layer\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "# Create the ResNet-20 model\n",
    "def ResNet_20():\n",
    "    return ResNet20(BasicBlock, [3, 3, 3])  # Each number represents 2n layers, so 3 blocks for each feature map size\n",
    "\n",
    "# Instantiate and print the model to verify its structure\n",
    "model = ResNet_20()\n",
    "\n",
    "# Print the model structure\n",
    "print(model)\n",
    "\n",
    "# Print the model structure\n",
    "print(model)\n",
    "shortcut_count = 0\n",
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, BasicBlock):\n",
    "        shortcut_count += 1\n",
    "\n",
    "print(f\"Total de shortcuts en el modelo: {shortcut_count}\")\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7_eC8lf5oryB"
   },
   "source": [
    "### ResNet32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HMkzQg2iot11",
    "outputId": "9d2d047d-93da-4034-a9f1-6511c72e27cb"
   },
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        # Conexión de atajo\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion * planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion * planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Función residual\n",
    "        out = F.relu(self.bn1(self.conv1(x)))  # Aplica BN y luego ReLU\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "# Modificar el modelo para devolver los embeddings de todas las capas\n",
    "class ResNet32(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet32, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        # Capa de convolución inicial\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # Capas residuales\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "\n",
    "        # Pooling global y capa completamente conectada\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.linear = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for s in strides:\n",
    "            layers.append(block(self.in_planes, planes, s))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convolución inicial\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        feature_maps['ReLUconv1'] = out\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        feature_maps['Layer2'] = out\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        feature_maps['Layer4'] = out\n",
    "        out = self.avgpool(out)\n",
    "        out = torch.flatten(out, 1)\n",
    "        # Capa completamente conectada\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "def ResNet_32():\n",
    "    return ResNet32(BasicBlock, [3, 4, 6, 2])\n",
    "\n",
    "model = ResNet_32()\n",
    "for name, param in model.named_parameters():\n",
    "    print(name)\n",
    "\n",
    "shortcut_count = 0\n",
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, BasicBlock):\n",
    "        shortcut_count += 1\n",
    "\n",
    "print(f\"Total de shortcuts en el modelo: {shortcut_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cR1lDcucoS3w"
   },
   "source": [
    "## Funciones para Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y4MvoVKu0nuw"
   },
   "outputs": [],
   "source": [
    "def show_gradients_Red_Plana_20(model):\n",
    "    layers_to_show = ['conv1', 'bn1', 'layer2.2.conv', 'layer2.2.bn', 'fc']  # Capas inicial, intermedia y final\n",
    "    for name, param in model.named_parameters():\n",
    "        if any(layer in name for layer in layers_to_show) and param.requires_grad and param.grad is not None:\n",
    "            grad = param.grad.cpu().numpy()\n",
    "            print(f\"Gradientes para {name}: min={grad.min()}, max={grad.max()}, mean={grad.mean()}, std={grad.std()}\")\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            plt.hist(grad.flatten(), bins=50)\n",
    "            plt.title(f'Gradientes para {name}')\n",
    "            plt.xlabel('Valor del gradiente')\n",
    "            plt.ylabel('Frecuencia')\n",
    "            plt.show()\n",
    "\n",
    "def show_gradients_Red_Plana_32(model):\n",
    "    layers_to_show = ['conv1', 'bn1', 'layer3.0', 'fc']  # Capas inicial, intermedia y final\n",
    "    for name, param in model.named_parameters():\n",
    "        if any(layer in name for layer in layers_to_show) and param.requires_grad and param.grad is not None:\n",
    "            grad = param.grad.cpu().numpy()\n",
    "            print(f\"Gradientes para {name}: min={grad.min()}, max={grad.max()}, mean={grad.mean()}, std={grad.std()}\")\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            plt.hist(grad.flatten(), bins=50)\n",
    "            plt.title(f'Gradientes para {name}')\n",
    "            plt.xlabel('Valor del gradiente')\n",
    "            plt.ylabel('Frecuencia')\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "def show_gradients_ResNet_20(model):\n",
    "    layers_to_show = ['conv1', 'bn1', 'layer2.1.conv1', 'layer2.1.bn1', 'linear']  # Capas inicial, intermedia y final\n",
    "    for name, param in model.named_parameters():\n",
    "        if any(layer in name for layer in layers_to_show) and param.requires_grad and param.grad is not None:\n",
    "            grad = param.grad.cpu().numpy()\n",
    "            print(f\"Gradientes para {name}: min={grad.min()}, max={grad.max()}, mean={grad.mean()}, std={grad.std()}\")\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            plt.hist(grad.flatten(), bins=50)\n",
    "            plt.title(f'Gradientes para {name}')\n",
    "            plt.xlabel('Valor del gradiente')\n",
    "            plt.ylabel('Frecuencia')\n",
    "            plt.show()\n",
    "\n",
    "def show_gradients_ResNet_32(model):\n",
    "    layers_to_show = ['conv1', 'bn1', 'layer2.1.conv1', 'layer2.1.bn1', 'linear']  # Capas inicial, intermedia y final\n",
    "    for name, param in model.named_parameters():\n",
    "        if any(layer in name for layer in layers_to_show) and param.requires_grad and param.grad is not None:\n",
    "            grad = param.grad.cpu().numpy()\n",
    "            print(f\"Gradientes para {name}: min={grad.min()}, max={grad.max()}, mean={grad.mean()}, std={grad.std()}\")\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            plt.hist(grad.flatten(), bins=50)\n",
    "            plt.title(f'Gradientes para {name}')\n",
    "            plt.xlabel('Valor del gradiente')\n",
    "            plt.ylabel('Frecuencia')\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Gc3HIJUoSoR"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Initialize He weights\n",
    "def initialize_weights_he(model):\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.Linear):\n",
    "            nn.init.kaiming_normal_(m.weight, a=0, mode='fan_out', nonlinearity='relu')\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.BatchNorm1d):\n",
    "            nn.init.constant_(m.weight, 1)\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "\n",
    "\n",
    "def show_curves(curves):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(13, 5))\n",
    "    fig.set_facecolor('white')\n",
    "\n",
    "    # Asegúrate de que los datos estén en la CPU antes de convertirlos a NumPy\n",
    "    epochs = np.arange(len(curves[\"val_loss\"])) + 1\n",
    "\n",
    "    ax[0].plot(epochs, np.array(curves['val_loss']), label='validation')\n",
    "    ax[0].plot(epochs, np.array(curves['train_loss']), label='training')\n",
    "    ax[0].set_xlabel('Epoch')\n",
    "    ax[0].set_ylabel('Loss')\n",
    "    ax[0].set_title('Loss evolution during training')\n",
    "    ax[0].legend()\n",
    "\n",
    "    ax[1].plot(epochs, np.array(curves['val_acc']), label='validation')\n",
    "    ax[1].plot(epochs, np.array(curves['train_acc']), label='training')\n",
    "    ax[1].set_xlabel('Epoch')\n",
    "    ax[1].set_ylabel('Accuracy')\n",
    "    ax[1].set_title('Accuracy evolution during training')\n",
    "    ax[1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_curves.png')\n",
    "    plt.show()\n",
    "\n",
    "# Visualize feature maps\n",
    "def show_feature_maps(feature_maps):\n",
    "    for layer_name, feature_map in feature_maps.items():\n",
    "        fmap = feature_map[0].cpu().numpy()  # Convert to CPU and NumPy for visualization\n",
    "        num_feature_maps = fmap.shape[0]\n",
    "\n",
    "        # Plot a grid of feature maps (first 8 feature maps)\n",
    "        fig, axes = plt.subplots(1, min(8, num_feature_maps), figsize=(20, 5))\n",
    "        fig.suptitle(f\"Feature Maps from Layer {layer_name}\", fontsize=16)\n",
    "\n",
    "        for i in range(min(8, num_feature_maps)):\n",
    "            axes[i].imshow(fmap[i], cmap='viridis')\n",
    "            axes[i].axis('off')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "def checkpoint_save(model, optimizer, epoch, filename):\n",
    "    checkpoint_data = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "    }\n",
    "    torch.save(checkpoint_data, os.path.join(checkpoint_dir, filename))\n",
    "    print(f\"Checkpoint guardado en {os.path.join(checkpoint_dir, filename)}\")\n",
    "\n",
    "def checkpoint_resume(model, optimizer, filename):\n",
    "    checkpoint_path = os.path.join(checkpoint_dir, filename)\n",
    "    if os.path.isfile(checkpoint_path):\n",
    "        checkpoint_data = torch.load(checkpoint_path)\n",
    "        model.load_state_dict(checkpoint_data['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint_data['optimizer_state_dict'])\n",
    "        epoch = checkpoint_data['epoch']\n",
    "        print(f\"Checkpoint cargado desde '{checkpoint_path}' (época {epoch})\")\n",
    "        return epoch\n",
    "    else:\n",
    "        print(f\"No se encontró ningún checkpoint en '{checkpoint_path}'\")\n",
    "        return None\n",
    "\n",
    "# Training step function\n",
    "def train_step(x_batch, y_batch, model, optimizer, criterion, device):\n",
    "    x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "    y_predicted = model(x_batch)\n",
    "    loss = criterion(y_predicted, y_batch)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return y_predicted, loss\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate(val_loader, model, criterion, device):\n",
    "    model.eval()\n",
    "    cumulative_loss = 0\n",
    "    cumulative_corrects = 0\n",
    "    data_count = 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in val_loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            final_output = model(imgs)\n",
    "            loss = criterion(final_output, labels)\n",
    "            cumulative_loss += loss.item() * len(labels)\n",
    "            data_count += len(labels)\n",
    "            _, pred_class = final_output.max(1)\n",
    "            cumulative_corrects += (pred_class == labels).sum().item()\n",
    "    val_acc = cumulative_corrects / data_count\n",
    "    val_loss = cumulative_loss / data_count\n",
    "    return val_acc, val_loss\n",
    "\n",
    "#Segunda Resnet\n",
    "def train_model(\n",
    "    model,\n",
    "    train_dataset,\n",
    "    val_dataset,\n",
    "    epochs,\n",
    "    max_iterations,\n",
    "    criterion,\n",
    "    batch_size,\n",
    "    lr,\n",
    "    weight_decay,\n",
    "    n_evaluations_per_epoch,\n",
    "    early_stop_thresh,  # Early stopping threshold\n",
    "    show_gradients,\n",
    "    patience,\n",
    "    use_gpu=True,\n",
    "    data_augmentation=False,\n",
    "    resume_checkpoint=None\n",
    "):\n",
    "    original_transform = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)),\n",
    "    ])\n",
    "\n",
    "    if data_augmentation:\n",
    "        train_dataset.dataset.transform = torchvision.transforms.Compose([\n",
    "            torchvision.transforms.RandomCrop(32, padding=4),\n",
    "            torchvision.transforms.RandomHorizontalFlip(),\n",
    "            torchvision.transforms.ToTensor(),\n",
    "            torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)),\n",
    "        ])\n",
    "    else:\n",
    "        train_dataset.dataset.transform = original_transform\n",
    "\n",
    "    print(f\"Using train transform: {train_dataset.dataset.transform}\")\n",
    "    print(f\"Using validation transform: {val_dataset.dataset.transform}\")\n",
    "\n",
    "\n",
    "    # Usar GPU si está disponible\n",
    "    device = 'cuda:0'#torch.device('cuda' if use_gpu else 'cpu')\n",
    "    model = model.to(device)\n",
    "\n",
    "    # DataLoaders\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=use_gpu)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=len(val_dataset), shuffle=False, pin_memory=use_gpu)\n",
    "\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=patience, threshold=0.0001, threshold_mode='abs')\n",
    "    scaler = torch.amp.GradScaler()\n",
    "\n",
    "    curves = {\"train_acc\": [], \"val_acc\": [], \"train_loss\": [], \"val_loss\": []}\n",
    "    t0 = time.perf_counter()\n",
    "    iteration = 0\n",
    "    n_batches = len(train_loader)\n",
    "    start_epoch = 0\n",
    "    if resume_checkpoint is not None:\n",
    "        start_epoch = checkpoint_resume(model, optimizer, resume_checkpoint)\n",
    "        print(f\"Reanudando desde la época {start_epoch}\")\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    best_epoch = -1\n",
    "    early_stop_counter = 0\n",
    "\n",
    "    for epoch in range(start_epoch, epochs):\n",
    "        print(optimizer.param_groups[0][\"lr\"])\n",
    "        print(f\"\\rEpoch {epoch + 1}/{epochs}\")\n",
    "        cumulative_train_loss = 0\n",
    "        cumulative_train_corrects = 0\n",
    "        train_loss_count = 0\n",
    "        train_acc_count = 0\n",
    "\n",
    "        model.train()\n",
    "        for i, (x_batch, y_batch) in enumerate(train_loader):\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "            y_predicted, loss = train_step(x_batch, y_batch, model, optimizer, criterion, device)\n",
    "\n",
    "            cumulative_train_loss += loss.item()\n",
    "            train_loss_count += 1\n",
    "            train_acc_count += y_batch.shape[0]\n",
    "\n",
    "            # Accuracy calculation\n",
    "            class_prediction = torch.argmax(y_predicted, axis=1).long()\n",
    "            cumulative_train_corrects += (y_batch == class_prediction).sum().item()\n",
    "\n",
    "\n",
    "            # Registro de métricas\n",
    "            if (i + 1) % (n_batches // n_evaluations_per_epoch) == 0:\n",
    "                train_loss = cumulative_train_loss / train_loss_count\n",
    "                train_acc = cumulative_train_corrects / train_acc_count\n",
    "\n",
    "                print(\n",
    "                    f\"Iteración {iteration + 1} - Lote {i + 1}/{n_batches} - \"\n",
    "                    f\"Pérdida de Entrenamiento: {train_loss:.4f}, Precisión de Entrenamiento: {train_acc:.4f}\"\n",
    "                )\n",
    "\n",
    "\n",
    "            iteration += 1\n",
    "            if iteration >= max_iterations:\n",
    "                print(f\"Número máximo de iteraciones alcanzado: {max_iterations}\")\n",
    "                break\n",
    "\n",
    "        val_acc, val_loss = evaluate(val_loader, model, criterion, device)\n",
    "        print(f\"Val loss: {val_loss:.4f}, Val acc: {val_acc:.4f}\")\n",
    "\n",
    "        train_loss = cumulative_train_loss / train_loss_count\n",
    "        train_acc = cumulative_train_corrects / train_acc_count\n",
    "\n",
    "        curves[\"train_acc\"].append(train_acc)\n",
    "        curves[\"val_acc\"].append(val_acc)\n",
    "        curves[\"train_loss\"].append(train_loss)\n",
    "        curves[\"val_loss\"].append(val_loss)\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        # Checkpointing the best model based on validation loss\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_epoch = epoch\n",
    "            early_stop_counter = 0\n",
    "            checkpoint_filename = f\"best_checkpoint_epoch_{epoch + 1}.pth\"\n",
    "            checkpoint_save(model, optimizer, epoch, checkpoint_filename)\n",
    "            print(f\"Checkpoint del mejor modelo guardado en la época {epoch + 1}\")\n",
    "        else:\n",
    "            early_stop_counter += 1\n",
    "\n",
    "        if epoch + 1 == 1 or (epoch + 1) % 5 == 0 or early_stop_counter >= early_stop_thresh:\n",
    "            show_gradients(model)\n",
    "            show_feature_maps(feature_maps)\n",
    "\n",
    "        if early_stop_counter >= early_stop_thresh:\n",
    "            print(f\"Early stopping at epoch {epoch + 1}\")\n",
    "            break\n",
    "\n",
    "        if iteration >= max_iterations:\n",
    "            break\n",
    "\n",
    "    total_time = time.perf_counter() - t0\n",
    "    print(f\"\\nTiempo total de entrenamiento: {total_time:.2f} segundos\")\n",
    "\n",
    "    # Ensure the model is on CPU after training\n",
    "    model.cpu()\n",
    "\n",
    "    if data_augmentation:\n",
    "        train_dataset.dataset.transform = original_transform\n",
    "\n",
    "    return curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ajKXL65t2-Aj"
   },
   "source": [
    "## Entrenamiento Distintos Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zU_flf7Z3Jsg"
   },
   "source": [
    "### RedPlana20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "JrymQVmc3Mk0",
    "outputId": "10080c96-71b4-4c90-d9dc-01d3f3a01081"
   },
   "outputs": [],
   "source": [
    "use_gpu = True\n",
    "\n",
    "# Checkpointing functions\n",
    "checkpoint_dir = \"/content/drive/MyDrive/CheckpointsRedPlana20\"\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "# Initialize feature map dictionary\n",
    "feature_maps = {}\n",
    "if __name__ == \"__main__\":\n",
    "    # Hiperparámetros\n",
    "    batch_size = 128\n",
    "    epochs = 70\n",
    "    max_iterations = 600000  # Ajusta según sea necesario\n",
    "    learning_rate = 0.1\n",
    "    n_evaluations_per_epoch = 10\n",
    "    use_gpu = torch.cuda.is_available()\n",
    "    data_augmentation = True\n",
    "    weight_decay = 0.0001\n",
    "    early_stop_thresh = 15\n",
    "    patience = 3\n",
    "\n",
    "    # Inicializar el modelo\n",
    "    model = PlainNet20(num_classes=10)\n",
    "    initialize_weights_he(model)\n",
    "    print(model)\n",
    "\n",
    "    # Definir función de pérdida\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Entrenar el modelo\n",
    "    curves = train_model(\n",
    "        model=model,\n",
    "        train_dataset=train_cifar10,\n",
    "        val_dataset=val_cifar10,\n",
    "        epochs=epochs,\n",
    "        max_iterations=max_iterations,\n",
    "        criterion=criterion,\n",
    "        batch_size=batch_size,\n",
    "        lr=learning_rate,\n",
    "        n_evaluations_per_epoch=n_evaluations_per_epoch,\n",
    "        early_stop_thresh=early_stop_thresh,\n",
    "        show_gradients=show_gradients_Red_Plana_20,\n",
    "        patience=patience,\n",
    "        use_gpu=use_gpu,\n",
    "        data_augmentation=data_augmentation,\n",
    "        resume_checkpoint=None,  # Establece a una cadena de caracteres para reanudar, por ejemplo, \"best_checkpoint_epoch_10.pth\"\n",
    "        weight_decay=weight_decay\n",
    "    )\n",
    "\n",
    "    # Plotear curvas de entrenamiento\n",
    "    show_curves(curves)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "psYE5IPM3skw",
    "outputId": "8b096974-4a44-4233-a458-0bf715910ed4"
   },
   "outputs": [],
   "source": [
    "use_gpu = True\n",
    "device = torch.device('cuda' if use_gpu else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# Obtener embeddings y realizar visualizaciones\n",
    "def get_embeddings(model, dataloader, use_gpu):\n",
    "    model.eval()  # Establecer el modelo en modo evaluación\n",
    "    device = torch.device('cuda' if use_gpu else 'cpu')\n",
    "    embeddings_list = []\n",
    "    labels_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Pasar los datos a través del modelo hasta antes de la capa totalmente conectada\n",
    "            out = F.relu((model.bn1(model.conv1(images))))\n",
    "            out = model.layer1(out)\n",
    "            out = model.layer2(out)\n",
    "            out = model.layer3(out)\n",
    "            out = model.avgpool(out)\n",
    "            out = out.view(out.size(0), -1)  # Aplanar las características\n",
    "\n",
    "            embeddings_list.append(out.cpu())\n",
    "            labels_list.append(labels.cpu())\n",
    "\n",
    "    embeddings = torch.cat(embeddings_list)\n",
    "    labels = torch.cat(labels_list)\n",
    "    return embeddings, labels\n",
    "\n",
    "\n",
    "# Crear un dataloader para todo el conjunto de entrenamiento\n",
    "full_train_loader = torch.utils.data.DataLoader(\n",
    "    train_cifar10, batch_size=128, shuffle=False, num_workers=2, pin_memory=use_gpu\n",
    ")\n",
    "\n",
    "# Obtener las embeddings\n",
    "embeddings, labels = get_embeddings(model, full_train_loader, use_gpu)\n",
    "# Convertir embeddings y labels a NumPy arrays\n",
    "embeddings_np = embeddings.numpy()\n",
    "labels_np = labels.numpy()\n",
    "\n",
    "# Visualización con t-SNE (Scikit-learn)\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Configurar t-SNE\n",
    "tsne = TSNE(n_components=2, perplexity=50, n_iter=1000, random_state=42)\n",
    "\n",
    "# Ajustar y transformar las embeddings\n",
    "embeddings_tsne = tsne.fit_transform(embeddings_np)\n",
    "\n",
    "# Graficar\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.scatterplot(\n",
    "    x=embeddings_tsne[:, 0], y=embeddings_tsne[:, 1],\n",
    "    hue=labels_np, palette=sns.color_palette(\"hls\", 10),\n",
    "    legend=\"full\", alpha=0.5\n",
    ")\n",
    "plt.title('t-SNE Dimensionality Reduction')\n",
    "plt.xlabel('Component 1')\n",
    "plt.ylabel('Component 2')\n",
    "plt.legend(title='Classes')\n",
    "plt.show()\n",
    "\n",
    "# Visualización con UMAP\n",
    "import umap.umap_ as umap\n",
    "\n",
    "# Configurar UMAP\n",
    "umap_reducer = umap.UMAP(\n",
    "    n_neighbors=30,\n",
    "    min_dist=0.1,\n",
    "    n_components=2,\n",
    "    metric='euclidean',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Ajustar y transformar las embeddings\n",
    "embeddings_umap = umap_reducer.fit_transform(embeddings_np)\n",
    "\n",
    "# Graficar\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.scatterplot(\n",
    "    x=embeddings_umap[:, 0], y=embeddings_umap[:, 1],\n",
    "    hue=labels_np, palette=sns.color_palette(\"hls\", 10),\n",
    "    legend=\"full\", alpha=0.5\n",
    ")\n",
    "plt.title('UMAP Dimensionality Reduction')\n",
    "plt.xlabel('Component 1')\n",
    "plt.ylabel('Component 2')\n",
    "plt.legend(title='Classes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sDN-LKP65yFJ"
   },
   "source": [
    "### RedPlana32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "CVPyHSt-5y-4",
    "outputId": "2702a20a-0fe8-42c4-ab2f-419dbc814d0e"
   },
   "outputs": [],
   "source": [
    "use_gpu = True\n",
    "\n",
    "# Checkpointing functions\n",
    "checkpoint_dir = \"/content/drive/MyDrive/CheckpointsRedPlana32\"\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "# Initialize feature map dictionary\n",
    "feature_maps = {}\n",
    "if __name__ == \"__main__\":\n",
    "    # Hiperparámetros\n",
    "    batch_size = 128\n",
    "    epochs = 70\n",
    "    max_iterations = 600000  # Ajusta según sea necesario\n",
    "    learning_rate = 0.1\n",
    "    n_evaluations_per_epoch = 10\n",
    "    use_gpu = torch.cuda.is_available()\n",
    "    data_augmentation = True\n",
    "    weight_decay = 0.0001\n",
    "    early_stop_thresh = 15\n",
    "    patience = 3\n",
    "\n",
    "    # Inicializar el modelo\n",
    "    model = PlainNet32(num_classes=10)\n",
    "    initialize_weights_he(model)\n",
    "    print(model)\n",
    "\n",
    "    # Definir función de pérdida\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Entrenar el modelo\n",
    "    curves = train_model(\n",
    "        model=model,\n",
    "        train_dataset=train_cifar10,\n",
    "        val_dataset=val_cifar10,\n",
    "        epochs=epochs,\n",
    "        max_iterations=max_iterations,\n",
    "        criterion=criterion,\n",
    "        batch_size=batch_size,\n",
    "        lr=learning_rate,\n",
    "        n_evaluations_per_epoch=n_evaluations_per_epoch,\n",
    "        early_stop_thresh=early_stop_thresh,\n",
    "        show_gradients=show_gradients_Red_Plana_20,\n",
    "        patience=patience,\n",
    "        use_gpu=use_gpu,\n",
    "        data_augmentation=data_augmentation,\n",
    "        resume_checkpoint=None,\n",
    "        weight_decay=weight_decay\n",
    "    )\n",
    "\n",
    "    # Plotear curvas de entrenamiento\n",
    "    show_curves(curves)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "yAzpuQYc7ffj",
    "outputId": "760a909e-6f8b-43cc-80c6-3f3293aee764"
   },
   "outputs": [],
   "source": [
    "use_gpu = True\n",
    "device = torch.device('cuda' if use_gpu else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# Obtener embeddings y realizar visualizaciones\n",
    "def get_embeddings(model, dataloader, use_gpu):\n",
    "    model.eval()  # Establecer el modelo en modo evaluación\n",
    "    device = torch.device('cuda' if use_gpu else 'cpu')\n",
    "    embeddings_list = []\n",
    "    labels_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Pasar los datos a través del modelo hasta antes de la capa totalmente conectada\n",
    "            out = F.relu(model.bn1(model.conv1(images)))\n",
    "            out = model.layer1(out)\n",
    "            out = model.layer2(out)\n",
    "            out = model.layer3(out)\n",
    "            out = model.layer4(out)\n",
    "            out = model.avgpool(out)\n",
    "            out = out.view(out.size(0), -1)  # Aplanar las características\n",
    "\n",
    "            embeddings_list.append(out.cpu())\n",
    "            labels_list.append(labels.cpu())\n",
    "\n",
    "    embeddings = torch.cat(embeddings_list)\n",
    "    labels = torch.cat(labels_list)\n",
    "    return embeddings, labels\n",
    "\n",
    "\n",
    "# Crear un dataloader para todo el conjunto de entrenamiento\n",
    "full_train_loader = torch.utils.data.DataLoader(\n",
    "    train_cifar10, batch_size=128, shuffle=False, num_workers=2, pin_memory=use_gpu\n",
    ")\n",
    "\n",
    "# Obtener las embeddings\n",
    "embeddings, labels = get_embeddings(model, full_train_loader, use_gpu)\n",
    "# Convertir embeddings y labels a NumPy arrays\n",
    "embeddings_np = embeddings.numpy()\n",
    "labels_np = labels.numpy()\n",
    "\n",
    "# Visualización con t-SNE (Scikit-learn)\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Configurar t-SNE\n",
    "tsne = TSNE(n_components=2, perplexity=50, n_iter=1000, random_state=42)\n",
    "\n",
    "# Ajustar y transformar las embeddings\n",
    "embeddings_tsne = tsne.fit_transform(embeddings_np)\n",
    "\n",
    "# Graficar\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.scatterplot(\n",
    "    x=embeddings_tsne[:, 0], y=embeddings_tsne[:, 1],\n",
    "    hue=labels_np, palette=sns.color_palette(\"hls\", 10),\n",
    "    legend=\"full\", alpha=0.5\n",
    ")\n",
    "plt.title('t-SNE Dimensionality Reduction')\n",
    "plt.xlabel('Component 1')\n",
    "plt.ylabel('Component 2')\n",
    "plt.legend(title='Classes')\n",
    "plt.show()\n",
    "\n",
    "# Visualización con UMAP\n",
    "import umap.umap_ as umap\n",
    "\n",
    "# Configurar UMAP\n",
    "umap_reducer = umap.UMAP(\n",
    "    n_neighbors=30,\n",
    "    min_dist=0.1,\n",
    "    n_components=2,\n",
    "    metric='euclidean',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Ajustar y transformar las embeddings\n",
    "embeddings_umap = umap_reducer.fit_transform(embeddings_np)\n",
    "\n",
    "# Graficar\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.scatterplot(\n",
    "    x=embeddings_umap[:, 0], y=embeddings_umap[:, 1],\n",
    "    hue=labels_np, palette=sns.color_palette(\"hls\", 10),\n",
    "    legend=\"full\", alpha=0.5\n",
    ")\n",
    "plt.title('UMAP Dimensionality Reduction')\n",
    "plt.xlabel('Component 1')\n",
    "plt.ylabel('Component 2')\n",
    "plt.legend(title='Classes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T2RjF3ku7oUe"
   },
   "source": [
    "### Resnet20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "sCc5UVL_7rja",
    "outputId": "9a79cf66-07c6-49db-8ccd-1df97ce4bf5d"
   },
   "outputs": [],
   "source": [
    "use_gpu = True\n",
    "\n",
    "# Checkpointing functions\n",
    "checkpoint_dir = \"/content/drive/MyDrive/CheckpointsResNet20\"\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "# Initialize feature map dictionary\n",
    "feature_maps = {}\n",
    "if __name__ == \"__main__\":\n",
    "    # Hiperparámetros\n",
    "    batch_size = 128\n",
    "    epochs = 70\n",
    "    max_iterations = 600000  # Ajusta según sea necesario\n",
    "    learning_rate = 0.1\n",
    "    n_evaluations_per_epoch = 10\n",
    "    use_gpu = torch.cuda.is_available()\n",
    "    data_augmentation = True\n",
    "    weight_decay = 0.0001\n",
    "    early_stop_thresh = 15\n",
    "    patience = 3\n",
    "\n",
    "    # Inicializar el modelo\n",
    "    model = ResNet_20()\n",
    "    initialize_weights_he(model)\n",
    "    print(model)\n",
    "\n",
    "    # Definir función de pérdida\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Entrenar el modelo\n",
    "    curves = train_model(\n",
    "        model=model,\n",
    "        train_dataset=train_cifar10,\n",
    "        val_dataset=val_cifar10,\n",
    "        epochs=epochs,\n",
    "        max_iterations=max_iterations,\n",
    "        criterion=criterion,\n",
    "        batch_size=batch_size,\n",
    "        lr=learning_rate,\n",
    "        n_evaluations_per_epoch=n_evaluations_per_epoch,\n",
    "        early_stop_thresh=early_stop_thresh,\n",
    "        show_gradients=show_gradients_ResNet_20,\n",
    "        patience=patience,\n",
    "        use_gpu=use_gpu,\n",
    "        data_augmentation=data_augmentation,\n",
    "        resume_checkpoint=None,  # Establece a una cadena de caracteres para reanudar, por ejemplo, \"best_checkpoint_epoch_10.pth\"\n",
    "        weight_decay=weight_decay\n",
    "    )\n",
    "\n",
    "    # Plotear curvas de entrenamiento\n",
    "    show_curves(curves)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "sDqNMSsh8LSK",
    "outputId": "8a268919-ce1c-4218-dfa4-fac63c7b512c"
   },
   "outputs": [],
   "source": [
    "use_gpu = True\n",
    "device = torch.device('cuda' if use_gpu else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# Obtener embeddings y realizar visualizaciones\n",
    "def get_embeddings(model, dataloader, use_gpu):\n",
    "    model.eval()  # Establecer el modelo en modo evaluación\n",
    "    device = torch.device('cuda' if use_gpu else 'cpu')\n",
    "    embeddings_list = []\n",
    "    labels_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Pasar los datos a través del modelo hasta antes de la capa totalmente conectada\n",
    "            out = model.relu(model.bn1(model.conv1(images)))\n",
    "            out = model.layer1(out)\n",
    "            out = model.layer2(out)\n",
    "            out = model.layer3(out)\n",
    "            out = model.avgpool(out)\n",
    "            out = out.view(out.size(0), -1)  # Aplanar las características\n",
    "\n",
    "            embeddings_list.append(out.cpu())\n",
    "            labels_list.append(labels.cpu())\n",
    "\n",
    "    embeddings = torch.cat(embeddings_list)\n",
    "    labels = torch.cat(labels_list)\n",
    "    return embeddings, labels\n",
    "\n",
    "\n",
    "# Crear un dataloader para todo el conjunto de entrenamiento\n",
    "full_train_loader = torch.utils.data.DataLoader(\n",
    "    train_cifar10, batch_size=128, shuffle=False, num_workers=2, pin_memory=use_gpu\n",
    ")\n",
    "\n",
    "# Obtener las embeddings\n",
    "embeddings, labels = get_embeddings(model, full_train_loader, use_gpu)\n",
    "# Convertir embeddings y labels a NumPy arrays\n",
    "embeddings_np = embeddings.numpy()\n",
    "labels_np = labels.numpy()\n",
    "\n",
    "# Visualización con t-SNE (Scikit-learn)\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Configurar t-SNE\n",
    "tsne = TSNE(n_components=2, perplexity=50, n_iter=1000, random_state=42)\n",
    "\n",
    "# Ajustar y transformar las embeddings\n",
    "embeddings_tsne = tsne.fit_transform(embeddings_np)\n",
    "\n",
    "# Graficar\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.scatterplot(\n",
    "    x=embeddings_tsne[:, 0], y=embeddings_tsne[:, 1],\n",
    "    hue=labels_np, palette=sns.color_palette(\"hls\", 10),\n",
    "    legend=\"full\", alpha=0.5\n",
    ")\n",
    "plt.title('t-SNE Dimensionality Reduction')\n",
    "plt.xlabel('Component 1')\n",
    "plt.ylabel('Component 2')\n",
    "plt.legend(title='Classes')\n",
    "plt.show()\n",
    "\n",
    "# Visualización con UMAP\n",
    "import umap.umap_ as umap\n",
    "\n",
    "# Configurar UMAP\n",
    "umap_reducer = umap.UMAP(\n",
    "    n_neighbors=30,\n",
    "    min_dist=0.1,\n",
    "    n_components=2,\n",
    "    metric='euclidean',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Ajustar y transformar las embeddings\n",
    "embeddings_umap = umap_reducer.fit_transform(embeddings_np)\n",
    "\n",
    "# Graficar\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.scatterplot(\n",
    "    x=embeddings_umap[:, 0], y=embeddings_umap[:, 1],\n",
    "    hue=labels_np, palette=sns.color_palette(\"hls\", 10),\n",
    "    legend=\"full\", alpha=0.5\n",
    ")\n",
    "plt.title('UMAP Dimensionality Reduction')\n",
    "plt.xlabel('Component 1')\n",
    "plt.ylabel('Component 2')\n",
    "plt.legend(title='Classes')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "X8dfIZsLmyE3",
    "Cn9e6XUSnucW",
    "mVMI4pGbm5Tf",
    "TwPsDYMQ0U-n",
    "7_eC8lf5oryB",
    "cR1lDcucoS3w"
   ],
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "EL4106",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
