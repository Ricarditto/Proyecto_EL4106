{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h15S9KnJjCWT",
    "outputId": "635fa23e-5c93-4759-9e78-4ffd36664c5d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ricar\\miniconda3\\envs\\EL4106\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Importaciones y preparaciones previas\n",
    "!pip install umap-learn\n",
    "\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import umap.umap_ as umap\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from sklearn.manifold import TSNE\n",
    "from torch import Tensor\n",
    "from typing import Type\n",
    "import torch.nn.init as init\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Iv9D_mJzetAe",
    "outputId": "5a43846f-35fa-4c91-fca8-dbf85a028a1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "ResNet110_SD(\n",
      "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (3): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (4): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (5): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (6): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (7): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (8): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (9): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (10): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (11): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (12): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (13): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (14): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (15): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (16): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (17): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): LambdaLayer()\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (3): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (4): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (5): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (6): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (7): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (8): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (9): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (10): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (11): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (12): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (13): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (14): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (15): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (16): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (17): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): LambdaLayer()\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (3): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (4): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (5): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (6): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (7): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (8): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (9): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (10): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (11): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (12): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (13): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (14): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (15): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (16): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (17): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (linear): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Transformaciones para entrenamiento y validación\n",
    "train_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomCrop(32, padding=4),  # Recorte aleatorio después del padding\n",
    "    torchvision.transforms.RandomHorizontalFlip(),      # Volteo horizontal aleatorio\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)),\n",
    "])\n",
    "\n",
    "val_test_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)),\n",
    "])\n",
    "\n",
    "# Cargar datasets CIFAR-10 con transformaciones\n",
    "train_cifar10 = torchvision.datasets.CIFAR10(\n",
    "    root=\"./cifar10\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=train_transform  # Se aplica data augmentation aquí\n",
    ")\n",
    "\n",
    "test_cifar10 = torchvision.datasets.CIFAR10(\n",
    "    root=\"./cifar10\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=val_test_transform  # Solo normalización para testing\n",
    ")\n",
    "\n",
    "# Dividir dataset de entrenamiento y validación\n",
    "train_cifar10, _ = torch.utils.data.random_split(train_cifar10, [45000, 5000], generator=torch.Generator().manual_seed(42))\n",
    "_, val_cifar10 = torch.utils.data.random_split(\n",
    "    torchvision.datasets.CIFAR10(root=\"./cifar10\", train=True, transform=val_test_transform),\n",
    "    [45000, 5000], generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "\"\"\"# ResNet con Profundidad Estocástica\"\"\"\n",
    "\n",
    "__all__ = ['resnet110']\n",
    "\n",
    "\n",
    "def _weights_init(m):\n",
    "    \"\"\"\n",
    "        Initialization of CNN weights\n",
    "    \"\"\"\n",
    "    classname = m.__class__.__name__\n",
    "    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
    "        init.kaiming_normal_(m.weight)\n",
    "\n",
    "class LambdaLayer(nn.Module):\n",
    "    \"\"\"\n",
    "      Identity mapping between ResNet blocks with different size feature map\n",
    "    \"\"\"\n",
    "    def __init__(self, lambd):\n",
    "        super(LambdaLayer, self).__init__()\n",
    "        self.lambd = lambd\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.lambd(x)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1, survival_prob=1.0, option='A'):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.survival_prob = survival_prob  # Probabilidad de supervivencia\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        # Conexión de atajo\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != planes:\n",
    "            if option == 'A':\n",
    "                \"\"\"\n",
    "                For CIFAR10 experiment, ResNet paper uses option A.\n",
    "                \"\"\"\n",
    "                self.shortcut = LambdaLayer(lambda x:\n",
    "                                            F.pad(x[:, :, ::2, ::2],\n",
    "                                                  (0, 0, 0, 0, planes // 4, planes // 4),\n",
    "                                                  \"constant\", 0))\n",
    "            elif option == 'B':\n",
    "                self.shortcut = nn.Sequential(\n",
    "                    nn.Conv2d(in_planes, planes * self.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                    nn.BatchNorm2d(planes * self.expansion)\n",
    "                )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training and torch.rand(1).item() > self.survival_prob:\n",
    "            # Si el bloque es \"saltado\", usa solo la conexión de atajo\n",
    "            return self.shortcut(x)\n",
    "        else:\n",
    "            # Si el bloque no es saltado, aplica la función residual\n",
    "            out = self.relu(self.bn1(self.conv1(x)))\n",
    "            out = self.bn2(self.conv2(out))\n",
    "            if not self.training:\n",
    "                out = out * self.survival_prob  # Escala la rama residual\n",
    "            out += self.shortcut(x)\n",
    "            out = self.relu(out)\n",
    "            return out\n",
    "\n",
    "\n",
    "\n",
    "class ResNet110_SD(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10, survival_prob=0.5):\n",
    "        super(ResNet110_SD, self).__init__()\n",
    "        self.in_planes = 16\n",
    "        self.survival_prob = survival_prob\n",
    "        self.num_blocks = sum(num_blocks)  # Número total de bloques\n",
    "        self.current_block = 0  # Contador de bloques para calcular survival_prob\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        # Capas residuales con decaimiento lineal de probabilidad\n",
    "        self.layer1 = self._make_layer(block, 16, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 64, num_blocks[2], stride=2)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.linear = nn.Linear(64 * block.expansion, num_classes)\n",
    "\n",
    "        self.apply(_weights_init)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for s in strides:\n",
    "            # Calcula survival_prob lineal para cada bloque\n",
    "            block_survival_prob = 1 - (self.current_block / self.num_blocks) * (1 - self.survival_prob)\n",
    "            self.current_block += 1\n",
    "            layers.append(block(self.in_planes, planes, s, survival_prob=block_survival_prob))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convolución inicial\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        feature_maps['ReLUconv1'] = out\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        feature_maps['Layer2'] = out\n",
    "        out = self.layer3(out)\n",
    "        feature_maps['Layer4'] = out\n",
    "        out = self.avgpool(out)\n",
    "        out = torch.flatten(out, 1)\n",
    "        # Capa completamente conectada\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "def resnet110_SD(survival_prob=0.5):\n",
    "    return ResNet110_SD(BasicBlock, [18, 18, 18], survival_prob=survival_prob)\n",
    "\n",
    "# Instancia del modelo para verificar\n",
    "model = resnet110_SD(survival_prob=0.5)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para mostrar los gradientes (sin cambios, excepto referencias a test)\n",
    "def show_gradients_ResNet_110(model):\n",
    "    layers_to_show = ['layer1.0.conv1', 'layer1.0.bn1', 'layer2.2.conv1', 'layer2.2.bn1', 'linear']  # Capas inicial, intermedia y final\n",
    "    for name, param in model.named_parameters():\n",
    "        if any(layer in name for layer in layers_to_show) and param.requires_grad and param.grad is not None:\n",
    "            grad = param.grad.cpu().numpy()\n",
    "            print(f\"Gradientes para {name}: min={grad.min()}, max={grad.max()}, mean={grad.mean()}, std={grad.std()}\")\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            plt.hist(grad.flatten(), bins=50)\n",
    "            plt.title(f'Gradientes para {name}')\n",
    "            plt.xlabel('Valor del gradiente')\n",
    "            plt.ylabel('Frecuencia')\n",
    "            plt.show()\n",
    "\n",
    "# Función para mostrar las curvas de pérdida y precisión\n",
    "def show_curves(curves):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(13, 5))\n",
    "    fig.set_facecolor('white')\n",
    "\n",
    "    epochs = np.arange(len(curves[\"val_loss\"])) + 1\n",
    "\n",
    "    # Pérdida\n",
    "    ax[0].plot(epochs, np.array(curves['train_loss']), label='Training Loss')\n",
    "    ax[0].plot(epochs, np.array(curves['val_loss']), label='Validation Loss')\n",
    "    ax[0].set_xlabel('Epoch')\n",
    "    ax[0].set_ylabel('Loss')\n",
    "    ax[0].set_title('Loss Evolution during Training')\n",
    "    ax[0].legend()\n",
    "\n",
    "    # Precisión\n",
    "    ax[1].plot(epochs, np.array(curves['train_acc']), label='Training Accuracy')\n",
    "    ax[1].plot(epochs, np.array(curves['val_acc']), label='Validation Accuracy')\n",
    "    ax[1].set_xlabel('Epoch')\n",
    "    ax[1].set_ylabel('Accuracy')\n",
    "    ax[1].set_title('Accuracy Evolution during Training')\n",
    "    ax[1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_curves.png')\n",
    "    plt.show()\n",
    "\n",
    "# Visualizar mapas de características (sin cambios)\n",
    "def show_feature_maps(feature_maps):\n",
    "    for layer_name, feature_map in feature_maps.items():\n",
    "        fmap = feature_map[0].cpu().numpy()  # Convert to CPU and NumPy for visualization\n",
    "        num_feature_maps = fmap.shape[0]\n",
    "\n",
    "        # Plot a grid of feature maps (first 8 feature maps)\n",
    "        fig, axes = plt.subplots(1, min(8, num_feature_maps), figsize=(20, 5))\n",
    "        fig.suptitle(f\"Feature Maps from Layer {layer_name}\", fontsize=16)\n",
    "\n",
    "        for i in range(min(8, num_feature_maps)):\n",
    "            axes[i].imshow(fmap[i], cmap='viridis')\n",
    "            axes[i].axis('off')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "# Training step function\n",
    "def train_step(x_batch, y_batch, model, optimizer, criterion, device):\n",
    "    x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "    y_predicted = model(x_batch)\n",
    "    loss = criterion(y_predicted, y_batch)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return y_predicted, loss\n",
    "\n",
    "# Funciones para guardar y cargar checkpoints (sin cambios)\n",
    "def checkpoint_save(model, optimizer, epoch, filename):\n",
    "    checkpoint_data = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "    }\n",
    "    torch.save(checkpoint_data, os.path.join(checkpoint_dir, filename))\n",
    "    print(f\"Checkpoint guardado en {os.path.join(checkpoint_dir, filename)}\")\n",
    "\n",
    "def checkpoint_resume(model, optimizer, filename):\n",
    "    checkpoint_path = os.path.join(checkpoint_dir, filename)\n",
    "    if os.path.isfile(checkpoint_path):\n",
    "        checkpoint_data = torch.load(checkpoint_path)\n",
    "        model.load_state_dict(checkpoint_data['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint_data['optimizer_state_dict'])\n",
    "        epoch = checkpoint_data['epoch']\n",
    "        print(f\"Checkpoint cargado desde '{checkpoint_path}' (época {epoch})\")\n",
    "        return epoch\n",
    "    else:\n",
    "        print(f\"No se encontró ningún checkpoint en '{checkpoint_path}'\")\n",
    "        return None\n",
    "\n",
    "# Evaluación (sin cambios, solo para validación ahora)\n",
    "def evaluate(val_loader, model, criterion, device):\n",
    "    model.eval()\n",
    "    cumulative_loss = 0\n",
    "    cumulative_corrects = 0\n",
    "    data_count = 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in val_loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            final_output = model(imgs)\n",
    "            loss = criterion(final_output, labels)\n",
    "            cumulative_loss += loss.item() * len(labels)\n",
    "            data_count += len(labels)\n",
    "            _, pred_class = final_output.max(1)\n",
    "            cumulative_corrects += (pred_class == labels).sum().item()\n",
    "    val_acc = cumulative_corrects / data_count\n",
    "    val_loss = cumulative_loss / data_count\n",
    "    return val_acc, val_loss\n",
    "\n",
    "# Función de entrenamiento\n",
    "def train_model(\n",
    "    model,\n",
    "    train_dataset,\n",
    "    val_dataset,\n",
    "    epochs,\n",
    "    max_iterations,\n",
    "    criterion,\n",
    "    batch_size,\n",
    "    lr,\n",
    "    weight_decay,\n",
    "    n_evaluations_per_epoch,\n",
    "    early_stop_thresh,\n",
    "    show_gradients,\n",
    "    patience,\n",
    "    use_gpu=True,\n",
    "    data_augmentation=False,\n",
    "    resume_checkpoint=None\n",
    "):\n",
    "    original_transform = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)),\n",
    "    ])\n",
    "\n",
    "    if data_augmentation:\n",
    "        train_dataset.dataset.transform = torchvision.transforms.Compose([\n",
    "            torchvision.transforms.RandomCrop(32, padding=4),\n",
    "            torchvision.transforms.RandomHorizontalFlip(),\n",
    "            torchvision.transforms.ToTensor(),\n",
    "            torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)),\n",
    "        ])\n",
    "    else:\n",
    "        train_dataset.dataset.transform = original_transform\n",
    "\n",
    "    print(f\"Using train transform: {train_dataset.dataset.transform}\")\n",
    "    print(f\"Using validation transform: {val_dataset.dataset.transform}\")\n",
    "\n",
    "    # Usar GPU si está disponible\n",
    "    device = torch.device('cuda' if use_gpu else 'cpu')\n",
    "    model = model.to(device)\n",
    "\n",
    "    # DataLoaders\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=use_gpu)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=4, pin_memory=use_gpu)\n",
    "\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=patience, threshold=0.0001, threshold_mode='abs')\n",
    "    scaler = torch.amp.GradScaler()\n",
    "    # Inicializar curvas solo para entrenamiento y validación\n",
    "    curves = {\"train_acc\": [], \"val_acc\": [],\n",
    "              \"train_loss\": [], \"val_loss\": [],\n",
    "              \"epoch_times\": []}\n",
    "    t0 = time.perf_counter()\n",
    "    iteration = 0\n",
    "    n_batches = len(train_loader)\n",
    "    start_epoch = 0\n",
    "    if resume_checkpoint is not None:\n",
    "        start_epoch = checkpoint_resume(model, optimizer, resume_checkpoint)\n",
    "        print(f\"Reanudando desde la época {start_epoch}\")\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    best_epoch = -1\n",
    "    early_stop_counter = 0\n",
    "\n",
    "    for epoch in range(start_epoch, epochs):\n",
    "        print(optimizer.param_groups[0][\"lr\"])\n",
    "        print(f\"\\rEpoch {epoch + 1}/{epochs}\")\n",
    "        cumulative_train_loss = 0\n",
    "        cumulative_train_corrects = 0\n",
    "        train_loss_count = 0\n",
    "        train_acc_count = 0\n",
    "\n",
    "        # Inicio de medición de tiempo por época\n",
    "        epoch_start_time = time.perf_counter()\n",
    "\n",
    "        model.train()\n",
    "        for i, (x_batch, y_batch) in enumerate(train_loader):\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "            y_predicted, loss = train_step(x_batch, y_batch, model, optimizer, criterion, device)\n",
    "\n",
    "            cumulative_train_loss += loss.item()\n",
    "            train_loss_count += 1\n",
    "            train_acc_count += y_batch.shape[0]\n",
    "\n",
    "            # Cálculo de precisión\n",
    "            class_prediction = torch.argmax(y_predicted, axis=1).long()\n",
    "            cumulative_train_corrects += (y_batch == class_prediction).sum().item()\n",
    "\n",
    "            # Registro de métricas\n",
    "            if (i + 1) % (n_batches // n_evaluations_per_epoch) == 0:\n",
    "                train_loss = cumulative_train_loss / train_loss_count\n",
    "                train_acc = cumulative_train_corrects / train_acc_count\n",
    "\n",
    "                print(\n",
    "                    f\"Iteración {iteration + 1} - Lote {i + 1}/{n_batches} - \"\n",
    "                    f\"Pérdida de Entrenamiento: {train_loss:.4f}, Precisión de Entrenamiento: {train_acc:.4f}\"\n",
    "                )\n",
    "\n",
    "            iteration += 1\n",
    "            if iteration >= max_iterations:\n",
    "                print(f\"Número máximo de iteraciones alcanzado: {max_iterations}\")\n",
    "                break\n",
    "\n",
    "        # Fin de medición de tiempo por época\n",
    "        epoch_end_time = time.perf_counter()\n",
    "        epoch_duration = epoch_end_time - epoch_start_time\n",
    "        curves[\"epoch_times\"].append(epoch_duration)\n",
    "\n",
    "        print(f\"Tiempo de la época {epoch + 1}: {epoch_duration:.2f} segundos\")\n",
    "\n",
    "        # Evaluación en el conjunto de validación\n",
    "        val_acc, val_loss = evaluate(val_loader, model, criterion, device)\n",
    "        print(f\"Val loss: {val_loss:.4f}, Val acc: {val_acc:.4f}\")\n",
    "\n",
    "        train_loss = cumulative_train_loss / train_loss_count\n",
    "        train_acc = cumulative_train_corrects / train_acc_count\n",
    "\n",
    "        curves[\"train_acc\"].append(train_acc)\n",
    "        curves[\"val_acc\"].append(val_acc)\n",
    "        curves[\"train_loss\"].append(train_loss)\n",
    "        curves[\"val_loss\"].append(val_loss)\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        # Checkpointing del mejor modelo basado en la pérdida de validación\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_epoch = epoch\n",
    "            early_stop_counter = 0\n",
    "            checkpoint_filename = f\"best_checkpoint_epoch_{epoch + 1}.pth\"\n",
    "            checkpoint_save(model, optimizer, epoch, checkpoint_filename)\n",
    "            print(f\"Checkpoint del mejor modelo guardado en la época {epoch + 1}\")\n",
    "        else:\n",
    "            early_stop_counter += 1\n",
    "\n",
    "        if early_stop_counter >= early_stop_thresh:\n",
    "            print(f\"Early stopping at epoch {epoch + 1}\")\n",
    "            break\n",
    "\n",
    "        if iteration >= max_iterations:\n",
    "            break\n",
    "\n",
    "    total_training_time = sum(curves[\"epoch_times\"])\n",
    "    print(f\"\\nTiempo total de entrenamiento: {total_training_time:.2f} segundos\")\n",
    "\n",
    "    # Asegurarse de que el modelo esté en CPU después del entrenamiento\n",
    "    model.cpu()\n",
    "\n",
    "    if data_augmentation:\n",
    "        train_dataset.dataset.transform = original_transform\n",
    "\n",
    "    return curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using train transform: Compose(\n",
      "    RandomCrop(size=(32, 32), padding=4)\n",
      "    RandomHorizontalFlip(p=0.5)\n",
      "    ToTensor()\n",
      "    Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.247, 0.243, 0.261))\n",
      ")\n",
      "Using validation transform: Compose(\n",
      "    ToTensor()\n",
      "    Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.247, 0.243, 0.261))\n",
      ")\n",
      "0.04\n",
      "Epoch 1/70\n",
      "Iteración 35 - Lote 35/352 - Pérdida de Entrenamiento: 5.4865, Precisión de Entrenamiento: 0.1062\n",
      "Iteración 70 - Lote 70/352 - Pérdida de Entrenamiento: 3.9358, Precisión de Entrenamiento: 0.1044\n",
      "Iteración 105 - Lote 105/352 - Pérdida de Entrenamiento: 3.3979, Precisión de Entrenamiento: 0.1028\n",
      "Iteración 140 - Lote 140/352 - Pérdida de Entrenamiento: 3.1279, Precisión de Entrenamiento: 0.1025\n",
      "Iteración 175 - Lote 175/352 - Pérdida de Entrenamiento: 2.9640, Precisión de Entrenamiento: 0.1037\n",
      "Iteración 210 - Lote 210/352 - Pérdida de Entrenamiento: 2.8527, Precisión de Entrenamiento: 0.1073\n",
      "Iteración 245 - Lote 245/352 - Pérdida de Entrenamiento: 2.7724, Precisión de Entrenamiento: 0.1086\n",
      "Iteración 280 - Lote 280/352 - Pérdida de Entrenamiento: 2.7124, Precisión de Entrenamiento: 0.1109\n",
      "Iteración 315 - Lote 315/352 - Pérdida de Entrenamiento: 2.6651, Precisión de Entrenamiento: 0.1121\n",
      "Iteración 350 - Lote 350/352 - Pérdida de Entrenamiento: 2.6256, Precisión de Entrenamiento: 0.1143\n",
      "Tiempo de la época 1: 144.30 segundos\n",
      "Val loss: 2.2819, Val acc: 0.1122\n",
      "Checkpoint guardado en CheckpointsResNet110_SD\\best_checkpoint_epoch_1.pth\n",
      "Checkpoint del mejor modelo guardado en la época 1\n",
      "0.04\n",
      "Epoch 2/70\n",
      "Iteración 387 - Lote 35/352 - Pérdida de Entrenamiento: 2.2630, Precisión de Entrenamiento: 0.1359\n",
      "Iteración 422 - Lote 70/352 - Pérdida de Entrenamiento: 2.2462, Precisión de Entrenamiento: 0.1454\n",
      "Iteración 457 - Lote 105/352 - Pérdida de Entrenamiento: 2.2235, Precisión de Entrenamiento: 0.1565\n",
      "Iteración 492 - Lote 140/352 - Pérdida de Entrenamiento: 2.1946, Precisión de Entrenamiento: 0.1647\n",
      "Iteración 527 - Lote 175/352 - Pérdida de Entrenamiento: 2.1715, Precisión de Entrenamiento: 0.1729\n",
      "Iteración 562 - Lote 210/352 - Pérdida de Entrenamiento: 2.1519, Precisión de Entrenamiento: 0.1812\n",
      "Iteración 597 - Lote 245/352 - Pérdida de Entrenamiento: 2.1323, Precisión de Entrenamiento: 0.1860\n",
      "Iteración 632 - Lote 280/352 - Pérdida de Entrenamiento: 2.1121, Precisión de Entrenamiento: 0.1921\n",
      "Iteración 667 - Lote 315/352 - Pérdida de Entrenamiento: 2.0947, Precisión de Entrenamiento: 0.1969\n",
      "Iteración 702 - Lote 350/352 - Pérdida de Entrenamiento: 2.0774, Precisión de Entrenamiento: 0.2050\n",
      "Tiempo de la época 2: 108.52 segundos\n",
      "Val loss: 1.8663, Val acc: 0.2832\n",
      "Checkpoint guardado en CheckpointsResNet110_SD\\best_checkpoint_epoch_2.pth\n",
      "Checkpoint del mejor modelo guardado en la época 2\n",
      "0.04\n",
      "Epoch 3/70\n",
      "Iteración 739 - Lote 35/352 - Pérdida de Entrenamiento: 1.9014, Precisión de Entrenamiento: 0.2728\n",
      "Iteración 774 - Lote 70/352 - Pérdida de Entrenamiento: 1.8908, Precisión de Entrenamiento: 0.2817\n",
      "Iteración 809 - Lote 105/352 - Pérdida de Entrenamiento: 1.8837, Precisión de Entrenamiento: 0.2839\n",
      "Iteración 844 - Lote 140/352 - Pérdida de Entrenamiento: 1.8665, Precisión de Entrenamiento: 0.2902\n",
      "Iteración 879 - Lote 175/352 - Pérdida de Entrenamiento: 1.8511, Precisión de Entrenamiento: 0.2942\n",
      "Iteración 914 - Lote 210/352 - Pérdida de Entrenamiento: 1.8413, Precisión de Entrenamiento: 0.2983\n",
      "Iteración 949 - Lote 245/352 - Pérdida de Entrenamiento: 1.8284, Precisión de Entrenamiento: 0.3016\n",
      "Iteración 984 - Lote 280/352 - Pérdida de Entrenamiento: 1.8216, Precisión de Entrenamiento: 0.3031\n",
      "Iteración 1019 - Lote 315/352 - Pérdida de Entrenamiento: 1.8121, Precisión de Entrenamiento: 0.3073\n",
      "Iteración 1054 - Lote 350/352 - Pérdida de Entrenamiento: 1.8037, Precisión de Entrenamiento: 0.3104\n",
      "Tiempo de la época 3: 101.35 segundos\n",
      "Val loss: 1.6537, Val acc: 0.3876\n",
      "Checkpoint guardado en CheckpointsResNet110_SD\\best_checkpoint_epoch_3.pth\n",
      "Checkpoint del mejor modelo guardado en la época 3\n",
      "0.04\n",
      "Epoch 4/70\n",
      "Iteración 1091 - Lote 35/352 - Pérdida de Entrenamiento: 1.6988, Precisión de Entrenamiento: 0.3551\n",
      "Iteración 1126 - Lote 70/352 - Pérdida de Entrenamiento: 1.6946, Precisión de Entrenamiento: 0.3556\n",
      "Iteración 1161 - Lote 105/352 - Pérdida de Entrenamiento: 1.6914, Precisión de Entrenamiento: 0.3571\n",
      "Iteración 1196 - Lote 140/352 - Pérdida de Entrenamiento: 1.6945, Precisión de Entrenamiento: 0.3566\n",
      "Iteración 1231 - Lote 175/352 - Pérdida de Entrenamiento: 1.6900, Precisión de Entrenamiento: 0.3588\n",
      "Iteración 1266 - Lote 210/352 - Pérdida de Entrenamiento: 1.6889, Precisión de Entrenamiento: 0.3594\n",
      "Iteración 1301 - Lote 245/352 - Pérdida de Entrenamiento: 1.6876, Precisión de Entrenamiento: 0.3625\n",
      "Iteración 1336 - Lote 280/352 - Pérdida de Entrenamiento: 1.6852, Precisión de Entrenamiento: 0.3641\n",
      "Iteración 1371 - Lote 315/352 - Pérdida de Entrenamiento: 1.6799, Precisión de Entrenamiento: 0.3673\n",
      "Iteración 1406 - Lote 350/352 - Pérdida de Entrenamiento: 1.6767, Precisión de Entrenamiento: 0.3698\n",
      "Tiempo de la época 4: 98.42 segundos\n",
      "Val loss: 1.5640, Val acc: 0.4182\n",
      "Checkpoint guardado en CheckpointsResNet110_SD\\best_checkpoint_epoch_4.pth\n",
      "Checkpoint del mejor modelo guardado en la época 4\n",
      "0.04\n",
      "Epoch 5/70\n",
      "Iteración 1443 - Lote 35/352 - Pérdida de Entrenamiento: 1.6397, Precisión de Entrenamiento: 0.3913\n",
      "Iteración 1478 - Lote 70/352 - Pérdida de Entrenamiento: 1.6267, Precisión de Entrenamiento: 0.3955\n",
      "Iteración 1513 - Lote 105/352 - Pérdida de Entrenamiento: 1.6159, Precisión de Entrenamiento: 0.4019\n",
      "Iteración 1548 - Lote 140/352 - Pérdida de Entrenamiento: 1.6065, Precisión de Entrenamiento: 0.4070\n",
      "Iteración 1583 - Lote 175/352 - Pérdida de Entrenamiento: 1.6020, Precisión de Entrenamiento: 0.4112\n",
      "Iteración 1618 - Lote 210/352 - Pérdida de Entrenamiento: 1.5866, Precisión de Entrenamiento: 0.4164\n",
      "Iteración 1653 - Lote 245/352 - Pérdida de Entrenamiento: 1.5792, Precisión de Entrenamiento: 0.4203\n",
      "Iteración 1688 - Lote 280/352 - Pérdida de Entrenamiento: 1.5688, Precisión de Entrenamiento: 0.4242\n",
      "Iteración 1723 - Lote 315/352 - Pérdida de Entrenamiento: 1.5614, Precisión de Entrenamiento: 0.4263\n",
      "Iteración 1758 - Lote 350/352 - Pérdida de Entrenamiento: 1.5556, Precisión de Entrenamiento: 0.4286\n",
      "Tiempo de la época 5: 98.54 segundos\n",
      "Val loss: 1.6082, Val acc: 0.4158\n",
      "0.04\n",
      "Epoch 6/70\n",
      "Iteración 1795 - Lote 35/352 - Pérdida de Entrenamiento: 1.4949, Precisión de Entrenamiento: 0.4348\n",
      "Iteración 1830 - Lote 70/352 - Pérdida de Entrenamiento: 1.4743, Precisión de Entrenamiento: 0.4526\n",
      "Iteración 1865 - Lote 105/352 - Pérdida de Entrenamiento: 1.4619, Precisión de Entrenamiento: 0.4643\n",
      "Iteración 1900 - Lote 140/352 - Pérdida de Entrenamiento: 1.4494, Precisión de Entrenamiento: 0.4691\n",
      "Iteración 1935 - Lote 175/352 - Pérdida de Entrenamiento: 1.4366, Precisión de Entrenamiento: 0.4760\n",
      "Iteración 1970 - Lote 210/352 - Pérdida de Entrenamiento: 1.4329, Precisión de Entrenamiento: 0.4789\n",
      "Iteración 2005 - Lote 245/352 - Pérdida de Entrenamiento: 1.4301, Precisión de Entrenamiento: 0.4809\n",
      "Iteración 2040 - Lote 280/352 - Pérdida de Entrenamiento: 1.4257, Precisión de Entrenamiento: 0.4814\n",
      "Iteración 2075 - Lote 315/352 - Pérdida de Entrenamiento: 1.4228, Precisión de Entrenamiento: 0.4827\n",
      "Iteración 2110 - Lote 350/352 - Pérdida de Entrenamiento: 1.4206, Precisión de Entrenamiento: 0.4829\n",
      "Tiempo de la época 6: 95.13 segundos\n",
      "Val loss: 1.3839, Val acc: 0.5060\n",
      "Checkpoint guardado en CheckpointsResNet110_SD\\best_checkpoint_epoch_6.pth\n",
      "Checkpoint del mejor modelo guardado en la época 6\n",
      "0.04\n",
      "Epoch 7/70\n",
      "Iteración 2147 - Lote 35/352 - Pérdida de Entrenamiento: 1.3462, Precisión de Entrenamiento: 0.5025\n",
      "Iteración 2182 - Lote 70/352 - Pérdida de Entrenamiento: 1.3339, Precisión de Entrenamiento: 0.5146\n",
      "Iteración 2217 - Lote 105/352 - Pérdida de Entrenamiento: 1.3198, Precisión de Entrenamiento: 0.5209\n",
      "Iteración 2252 - Lote 140/352 - Pérdida de Entrenamiento: 1.3010, Precisión de Entrenamiento: 0.5281\n",
      "Iteración 2287 - Lote 175/352 - Pérdida de Entrenamiento: 1.3023, Precisión de Entrenamiento: 0.5289\n",
      "Iteración 2322 - Lote 210/352 - Pérdida de Entrenamiento: 1.2981, Precisión de Entrenamiento: 0.5311\n",
      "Iteración 2357 - Lote 245/352 - Pérdida de Entrenamiento: 1.2961, Precisión de Entrenamiento: 0.5313\n",
      "Iteración 2392 - Lote 280/352 - Pérdida de Entrenamiento: 1.2915, Precisión de Entrenamiento: 0.5344\n",
      "Iteración 2427 - Lote 315/352 - Pérdida de Entrenamiento: 1.2867, Precisión de Entrenamiento: 0.5360\n",
      "Iteración 2462 - Lote 350/352 - Pérdida de Entrenamiento: 1.2828, Precisión de Entrenamiento: 0.5377\n",
      "Tiempo de la época 7: 89.81 segundos\n",
      "Val loss: 1.2503, Val acc: 0.5650\n",
      "Checkpoint guardado en CheckpointsResNet110_SD\\best_checkpoint_epoch_7.pth\n",
      "Checkpoint del mejor modelo guardado en la época 7\n",
      "0.04\n",
      "Epoch 8/70\n",
      "Iteración 2499 - Lote 35/352 - Pérdida de Entrenamiento: 1.1958, Precisión de Entrenamiento: 0.5641\n",
      "Iteración 2534 - Lote 70/352 - Pérdida de Entrenamiento: 1.2028, Precisión de Entrenamiento: 0.5634\n",
      "Iteración 2569 - Lote 105/352 - Pérdida de Entrenamiento: 1.1959, Precisión de Entrenamiento: 0.5684\n",
      "Iteración 2604 - Lote 140/352 - Pérdida de Entrenamiento: 1.2017, Precisión de Entrenamiento: 0.5675\n",
      "Iteración 2639 - Lote 175/352 - Pérdida de Entrenamiento: 1.1936, Precisión de Entrenamiento: 0.5698\n",
      "Iteración 2674 - Lote 210/352 - Pérdida de Entrenamiento: 1.1848, Precisión de Entrenamiento: 0.5732\n",
      "Iteración 2709 - Lote 245/352 - Pérdida de Entrenamiento: 1.1805, Precisión de Entrenamiento: 0.5746\n",
      "Iteración 2744 - Lote 280/352 - Pérdida de Entrenamiento: 1.1781, Precisión de Entrenamiento: 0.5763\n",
      "Iteración 2779 - Lote 315/352 - Pérdida de Entrenamiento: 1.1749, Precisión de Entrenamiento: 0.5780\n",
      "Iteración 2814 - Lote 350/352 - Pérdida de Entrenamiento: 1.1692, Precisión de Entrenamiento: 0.5804\n",
      "Tiempo de la época 8: 90.70 segundos\n",
      "Val loss: 1.1301, Val acc: 0.5968\n",
      "Checkpoint guardado en CheckpointsResNet110_SD\\best_checkpoint_epoch_8.pth\n",
      "Checkpoint del mejor modelo guardado en la época 8\n",
      "0.04\n",
      "Epoch 9/70\n",
      "Iteración 2851 - Lote 35/352 - Pérdida de Entrenamiento: 1.1066, Precisión de Entrenamiento: 0.6087\n",
      "Iteración 2886 - Lote 70/352 - Pérdida de Entrenamiento: 1.1117, Precisión de Entrenamiento: 0.6039\n",
      "Iteración 2921 - Lote 105/352 - Pérdida de Entrenamiento: 1.1007, Precisión de Entrenamiento: 0.6055\n",
      "Iteración 2956 - Lote 140/352 - Pérdida de Entrenamiento: 1.0926, Precisión de Entrenamiento: 0.6103\n",
      "Iteración 2991 - Lote 175/352 - Pérdida de Entrenamiento: 1.0917, Precisión de Entrenamiento: 0.6107\n",
      "Iteración 3026 - Lote 210/352 - Pérdida de Entrenamiento: 1.0867, Precisión de Entrenamiento: 0.6122\n",
      "Iteración 3061 - Lote 245/352 - Pérdida de Entrenamiento: 1.0879, Precisión de Entrenamiento: 0.6114\n",
      "Iteración 3096 - Lote 280/352 - Pérdida de Entrenamiento: 1.0817, Precisión de Entrenamiento: 0.6136\n",
      "Iteración 3131 - Lote 315/352 - Pérdida de Entrenamiento: 1.0783, Precisión de Entrenamiento: 0.6156\n",
      "Iteración 3166 - Lote 350/352 - Pérdida de Entrenamiento: 1.0695, Precisión de Entrenamiento: 0.6187\n",
      "Tiempo de la época 9: 91.75 segundos\n",
      "Val loss: 0.9328, Val acc: 0.6718\n",
      "Checkpoint guardado en CheckpointsResNet110_SD\\best_checkpoint_epoch_9.pth\n",
      "Checkpoint del mejor modelo guardado en la época 9\n",
      "0.04\n",
      "Epoch 10/70\n",
      "Iteración 3203 - Lote 35/352 - Pérdida de Entrenamiento: 1.0197, Precisión de Entrenamiento: 0.6413\n",
      "Iteración 3238 - Lote 70/352 - Pérdida de Entrenamiento: 1.0083, Precisión de Entrenamiento: 0.6403\n",
      "Iteración 3273 - Lote 105/352 - Pérdida de Entrenamiento: 1.0060, Precisión de Entrenamiento: 0.6432\n",
      "Iteración 3308 - Lote 140/352 - Pérdida de Entrenamiento: 0.9997, Precisión de Entrenamiento: 0.6439\n",
      "Iteración 3343 - Lote 175/352 - Pérdida de Entrenamiento: 0.9994, Precisión de Entrenamiento: 0.6457\n",
      "Iteración 3378 - Lote 210/352 - Pérdida de Entrenamiento: 0.9948, Precisión de Entrenamiento: 0.6473\n",
      "Iteración 3413 - Lote 245/352 - Pérdida de Entrenamiento: 0.9914, Precisión de Entrenamiento: 0.6485\n",
      "Iteración 3448 - Lote 280/352 - Pérdida de Entrenamiento: 0.9860, Precisión de Entrenamiento: 0.6502\n",
      "Iteración 3483 - Lote 315/352 - Pérdida de Entrenamiento: 0.9830, Precisión de Entrenamiento: 0.6519\n",
      "Iteración 3518 - Lote 350/352 - Pérdida de Entrenamiento: 0.9814, Precisión de Entrenamiento: 0.6528\n",
      "Tiempo de la época 10: 93.52 segundos\n",
      "Val loss: 0.9128, Val acc: 0.6820\n",
      "Checkpoint guardado en CheckpointsResNet110_SD\\best_checkpoint_epoch_10.pth\n",
      "Checkpoint del mejor modelo guardado en la época 10\n",
      "0.04\n",
      "Epoch 11/70\n",
      "Iteración 3555 - Lote 35/352 - Pérdida de Entrenamiento: 0.9221, Precisión de Entrenamiento: 0.6654\n",
      "Iteración 3590 - Lote 70/352 - Pérdida de Entrenamiento: 0.9240, Precisión de Entrenamiento: 0.6681\n",
      "Iteración 3625 - Lote 105/352 - Pérdida de Entrenamiento: 0.9196, Precisión de Entrenamiento: 0.6696\n",
      "Iteración 3660 - Lote 140/352 - Pérdida de Entrenamiento: 0.9239, Precisión de Entrenamiento: 0.6693\n",
      "Iteración 3695 - Lote 175/352 - Pérdida de Entrenamiento: 0.9283, Precisión de Entrenamiento: 0.6698\n",
      "Iteración 3730 - Lote 210/352 - Pérdida de Entrenamiento: 0.9218, Precisión de Entrenamiento: 0.6722\n",
      "Iteración 3765 - Lote 245/352 - Pérdida de Entrenamiento: 0.9154, Precisión de Entrenamiento: 0.6744\n",
      "Iteración 3800 - Lote 280/352 - Pérdida de Entrenamiento: 0.9153, Precisión de Entrenamiento: 0.6746\n",
      "Iteración 3835 - Lote 315/352 - Pérdida de Entrenamiento: 0.9112, Precisión de Entrenamiento: 0.6768\n",
      "Iteración 3870 - Lote 350/352 - Pérdida de Entrenamiento: 0.9095, Precisión de Entrenamiento: 0.6772\n",
      "Tiempo de la época 11: 96.80 segundos\n",
      "Val loss: 0.8789, Val acc: 0.6902\n",
      "Checkpoint guardado en CheckpointsResNet110_SD\\best_checkpoint_epoch_11.pth\n",
      "Checkpoint del mejor modelo guardado en la época 11\n",
      "0.04\n",
      "Epoch 12/70\n",
      "Iteración 3907 - Lote 35/352 - Pérdida de Entrenamiento: 0.8589, Precisión de Entrenamiento: 0.6993\n",
      "Iteración 3942 - Lote 70/352 - Pérdida de Entrenamiento: 0.8706, Precisión de Entrenamiento: 0.6935\n",
      "Iteración 3977 - Lote 105/352 - Pérdida de Entrenamiento: 0.8583, Precisión de Entrenamiento: 0.6971\n",
      "Iteración 4012 - Lote 140/352 - Pérdida de Entrenamiento: 0.8468, Precisión de Entrenamiento: 0.7020\n",
      "Iteración 4047 - Lote 175/352 - Pérdida de Entrenamiento: 0.8458, Precisión de Entrenamiento: 0.7029\n",
      "Iteración 4082 - Lote 210/352 - Pérdida de Entrenamiento: 0.8460, Precisión de Entrenamiento: 0.7021\n",
      "Iteración 4117 - Lote 245/352 - Pérdida de Entrenamiento: 0.8414, Precisión de Entrenamiento: 0.7030\n",
      "Iteración 4152 - Lote 280/352 - Pérdida de Entrenamiento: 0.8416, Precisión de Entrenamiento: 0.7030\n",
      "Iteración 4187 - Lote 315/352 - Pérdida de Entrenamiento: 0.8369, Precisión de Entrenamiento: 0.7047\n",
      "Iteración 4222 - Lote 350/352 - Pérdida de Entrenamiento: 0.8373, Precisión de Entrenamiento: 0.7056\n",
      "Tiempo de la época 12: 96.12 segundos\n",
      "Val loss: 0.8441, Val acc: 0.7024\n",
      "Checkpoint guardado en CheckpointsResNet110_SD\\best_checkpoint_epoch_12.pth\n",
      "Checkpoint del mejor modelo guardado en la época 12\n",
      "0.04\n",
      "Epoch 13/70\n",
      "Iteración 4259 - Lote 35/352 - Pérdida de Entrenamiento: 0.7961, Precisión de Entrenamiento: 0.7239\n",
      "Iteración 4294 - Lote 70/352 - Pérdida de Entrenamiento: 0.7896, Precisión de Entrenamiento: 0.7277\n",
      "Iteración 4329 - Lote 105/352 - Pérdida de Entrenamiento: 0.7980, Precisión de Entrenamiento: 0.7228\n",
      "Iteración 4364 - Lote 140/352 - Pérdida de Entrenamiento: 0.7894, Precisión de Entrenamiento: 0.7248\n",
      "Iteración 4399 - Lote 175/352 - Pérdida de Entrenamiento: 0.7871, Precisión de Entrenamiento: 0.7245\n",
      "Iteración 4434 - Lote 210/352 - Pérdida de Entrenamiento: 0.7876, Precisión de Entrenamiento: 0.7237\n",
      "Iteración 4469 - Lote 245/352 - Pérdida de Entrenamiento: 0.7880, Precisión de Entrenamiento: 0.7248\n",
      "Iteración 4504 - Lote 280/352 - Pérdida de Entrenamiento: 0.7866, Precisión de Entrenamiento: 0.7258\n",
      "Iteración 4539 - Lote 315/352 - Pérdida de Entrenamiento: 0.7831, Precisión de Entrenamiento: 0.7261\n",
      "Iteración 4574 - Lote 350/352 - Pérdida de Entrenamiento: 0.7813, Precisión de Entrenamiento: 0.7266\n",
      "Tiempo de la época 13: 98.19 segundos\n",
      "Val loss: 0.7295, Val acc: 0.7500\n",
      "Checkpoint guardado en CheckpointsResNet110_SD\\best_checkpoint_epoch_13.pth\n",
      "Checkpoint del mejor modelo guardado en la época 13\n",
      "0.04\n",
      "Epoch 14/70\n",
      "Iteración 4611 - Lote 35/352 - Pérdida de Entrenamiento: 0.7575, Precisión de Entrenamiento: 0.7315\n",
      "Iteración 4646 - Lote 70/352 - Pérdida de Entrenamiento: 0.7548, Precisión de Entrenamiento: 0.7346\n",
      "Iteración 4681 - Lote 105/352 - Pérdida de Entrenamiento: 0.7511, Precisión de Entrenamiento: 0.7396\n",
      "Iteración 4716 - Lote 140/352 - Pérdida de Entrenamiento: 0.7565, Precisión de Entrenamiento: 0.7353\n",
      "Iteración 4751 - Lote 175/352 - Pérdida de Entrenamiento: 0.7545, Precisión de Entrenamiento: 0.7350\n",
      "Iteración 4786 - Lote 210/352 - Pérdida de Entrenamiento: 0.7503, Precisión de Entrenamiento: 0.7368\n",
      "Iteración 4821 - Lote 245/352 - Pérdida de Entrenamiento: 0.7432, Precisión de Entrenamiento: 0.7383\n",
      "Iteración 4856 - Lote 280/352 - Pérdida de Entrenamiento: 0.7438, Precisión de Entrenamiento: 0.7390\n",
      "Iteración 4891 - Lote 315/352 - Pérdida de Entrenamiento: 0.7399, Precisión de Entrenamiento: 0.7405\n",
      "Iteración 4926 - Lote 350/352 - Pérdida de Entrenamiento: 0.7397, Precisión de Entrenamiento: 0.7408\n",
      "Tiempo de la época 14: 97.98 segundos\n",
      "Val loss: 0.7277, Val acc: 0.7552\n",
      "Checkpoint guardado en CheckpointsResNet110_SD\\best_checkpoint_epoch_14.pth\n",
      "Checkpoint del mejor modelo guardado en la época 14\n",
      "0.04\n",
      "Epoch 15/70\n",
      "Iteración 4963 - Lote 35/352 - Pérdida de Entrenamiento: 0.7258, Precisión de Entrenamiento: 0.7473\n",
      "Iteración 4998 - Lote 70/352 - Pérdida de Entrenamiento: 0.7033, Precisión de Entrenamiento: 0.7548\n",
      "Iteración 5033 - Lote 105/352 - Pérdida de Entrenamiento: 0.7139, Precisión de Entrenamiento: 0.7520\n",
      "Iteración 5068 - Lote 140/352 - Pérdida de Entrenamiento: 0.7142, Precisión de Entrenamiento: 0.7495\n",
      "Iteración 5103 - Lote 175/352 - Pérdida de Entrenamiento: 0.7179, Precisión de Entrenamiento: 0.7504\n",
      "Iteración 5138 - Lote 210/352 - Pérdida de Entrenamiento: 0.7143, Precisión de Entrenamiento: 0.7511\n",
      "Iteración 5173 - Lote 245/352 - Pérdida de Entrenamiento: 0.7105, Precisión de Entrenamiento: 0.7527\n",
      "Iteración 5208 - Lote 280/352 - Pérdida de Entrenamiento: 0.7105, Precisión de Entrenamiento: 0.7526\n",
      "Iteración 5243 - Lote 315/352 - Pérdida de Entrenamiento: 0.7089, Precisión de Entrenamiento: 0.7526\n",
      "Iteración 5278 - Lote 350/352 - Pérdida de Entrenamiento: 0.7086, Precisión de Entrenamiento: 0.7525\n",
      "Tiempo de la época 15: 97.60 segundos\n",
      "Val loss: 0.6385, Val acc: 0.7788\n",
      "Checkpoint guardado en CheckpointsResNet110_SD\\best_checkpoint_epoch_15.pth\n",
      "Checkpoint del mejor modelo guardado en la época 15\n",
      "0.04\n",
      "Epoch 16/70\n",
      "Iteración 5315 - Lote 35/352 - Pérdida de Entrenamiento: 0.7005, Precisión de Entrenamiento: 0.7580\n",
      "Iteración 5350 - Lote 70/352 - Pérdida de Entrenamiento: 0.6684, Precisión de Entrenamiento: 0.7683\n",
      "Iteración 5385 - Lote 105/352 - Pérdida de Entrenamiento: 0.6656, Precisión de Entrenamiento: 0.7684\n",
      "Iteración 5420 - Lote 140/352 - Pérdida de Entrenamiento: 0.6624, Precisión de Entrenamiento: 0.7702\n",
      "Iteración 5455 - Lote 175/352 - Pérdida de Entrenamiento: 0.6642, Precisión de Entrenamiento: 0.7696\n",
      "Iteración 5490 - Lote 210/352 - Pérdida de Entrenamiento: 0.6621, Precisión de Entrenamiento: 0.7702\n",
      "Iteración 5525 - Lote 245/352 - Pérdida de Entrenamiento: 0.6604, Precisión de Entrenamiento: 0.7721\n",
      "Iteración 5560 - Lote 280/352 - Pérdida de Entrenamiento: 0.6600, Precisión de Entrenamiento: 0.7724\n",
      "Iteración 5595 - Lote 315/352 - Pérdida de Entrenamiento: 0.6596, Precisión de Entrenamiento: 0.7720\n",
      "Iteración 5630 - Lote 350/352 - Pérdida de Entrenamiento: 0.6617, Precisión de Entrenamiento: 0.7716\n",
      "Tiempo de la época 16: 99.01 segundos\n",
      "Val loss: 0.6619, Val acc: 0.7662\n",
      "0.04\n",
      "Epoch 17/70\n",
      "Iteración 5667 - Lote 35/352 - Pérdida de Entrenamiento: 0.6417, Precisión de Entrenamiento: 0.7868\n",
      "Iteración 5702 - Lote 70/352 - Pérdida de Entrenamiento: 0.6385, Precisión de Entrenamiento: 0.7831\n",
      "Iteración 5737 - Lote 105/352 - Pérdida de Entrenamiento: 0.6296, Precisión de Entrenamiento: 0.7821\n",
      "Iteración 5772 - Lote 140/352 - Pérdida de Entrenamiento: 0.6348, Precisión de Entrenamiento: 0.7794\n",
      "Iteración 5807 - Lote 175/352 - Pérdida de Entrenamiento: 0.6386, Precisión de Entrenamiento: 0.7777\n",
      "Iteración 5842 - Lote 210/352 - Pérdida de Entrenamiento: 0.6395, Precisión de Entrenamiento: 0.7777\n",
      "Iteración 5877 - Lote 245/352 - Pérdida de Entrenamiento: 0.6387, Precisión de Entrenamiento: 0.7772\n",
      "Iteración 5912 - Lote 280/352 - Pérdida de Entrenamiento: 0.6390, Precisión de Entrenamiento: 0.7768\n",
      "Iteración 5947 - Lote 315/352 - Pérdida de Entrenamiento: 0.6350, Precisión de Entrenamiento: 0.7780\n",
      "Iteración 5982 - Lote 350/352 - Pérdida de Entrenamiento: 0.6329, Precisión de Entrenamiento: 0.7789\n",
      "Tiempo de la época 17: 97.57 segundos\n",
      "Val loss: 0.6269, Val acc: 0.7860\n",
      "Checkpoint guardado en CheckpointsResNet110_SD\\best_checkpoint_epoch_17.pth\n",
      "Checkpoint del mejor modelo guardado en la época 17\n",
      "0.04\n",
      "Epoch 18/70\n",
      "Iteración 6019 - Lote 35/352 - Pérdida de Entrenamiento: 0.5913, Precisión de Entrenamiento: 0.7942\n",
      "Iteración 6054 - Lote 70/352 - Pérdida de Entrenamiento: 0.6055, Precisión de Entrenamiento: 0.7882\n",
      "Iteración 6089 - Lote 105/352 - Pérdida de Entrenamiento: 0.5999, Precisión de Entrenamiento: 0.7923\n",
      "Iteración 6124 - Lote 140/352 - Pérdida de Entrenamiento: 0.6137, Precisión de Entrenamiento: 0.7873\n",
      "Iteración 6159 - Lote 175/352 - Pérdida de Entrenamiento: 0.6062, Precisión de Entrenamiento: 0.7904\n",
      "Iteración 6194 - Lote 210/352 - Pérdida de Entrenamiento: 0.6046, Precisión de Entrenamiento: 0.7905\n",
      "Iteración 6229 - Lote 245/352 - Pérdida de Entrenamiento: 0.6039, Precisión de Entrenamiento: 0.7903\n",
      "Iteración 6264 - Lote 280/352 - Pérdida de Entrenamiento: 0.6060, Precisión de Entrenamiento: 0.7898\n",
      "Iteración 6299 - Lote 315/352 - Pérdida de Entrenamiento: 0.6067, Precisión de Entrenamiento: 0.7892\n",
      "Iteración 6334 - Lote 350/352 - Pérdida de Entrenamiento: 0.6045, Precisión de Entrenamiento: 0.7902\n",
      "Tiempo de la época 18: 98.02 segundos\n",
      "Val loss: 0.5662, Val acc: 0.8048\n",
      "Checkpoint guardado en CheckpointsResNet110_SD\\best_checkpoint_epoch_18.pth\n",
      "Checkpoint del mejor modelo guardado en la época 18\n",
      "0.04\n",
      "Epoch 19/70\n",
      "Iteración 6371 - Lote 35/352 - Pérdida de Entrenamiento: 0.5699, Precisión de Entrenamiento: 0.7978\n",
      "Iteración 6406 - Lote 70/352 - Pérdida de Entrenamiento: 0.5822, Precisión de Entrenamiento: 0.7948\n",
      "Iteración 6441 - Lote 105/352 - Pérdida de Entrenamiento: 0.5815, Precisión de Entrenamiento: 0.7967\n",
      "Iteración 6476 - Lote 140/352 - Pérdida de Entrenamiento: 0.5883, Precisión de Entrenamiento: 0.7958\n",
      "Iteración 6511 - Lote 175/352 - Pérdida de Entrenamiento: 0.5879, Precisión de Entrenamiento: 0.7968\n",
      "Iteración 6546 - Lote 210/352 - Pérdida de Entrenamiento: 0.5884, Precisión de Entrenamiento: 0.7972\n",
      "Iteración 6581 - Lote 245/352 - Pérdida de Entrenamiento: 0.5886, Precisión de Entrenamiento: 0.7971\n",
      "Iteración 6616 - Lote 280/352 - Pérdida de Entrenamiento: 0.5867, Precisión de Entrenamiento: 0.7977\n",
      "Iteración 6651 - Lote 315/352 - Pérdida de Entrenamiento: 0.5883, Precisión de Entrenamiento: 0.7976\n",
      "Iteración 6686 - Lote 350/352 - Pérdida de Entrenamiento: 0.5852, Precisión de Entrenamiento: 0.7984\n",
      "Tiempo de la época 19: 99.73 segundos\n",
      "Val loss: 0.6155, Val acc: 0.7946\n",
      "0.04\n",
      "Epoch 20/70\n",
      "Iteración 6723 - Lote 35/352 - Pérdida de Entrenamiento: 0.5449, Precisión de Entrenamiento: 0.8158\n",
      "Iteración 6758 - Lote 70/352 - Pérdida de Entrenamiento: 0.5578, Precisión de Entrenamiento: 0.8085\n",
      "Iteración 6793 - Lote 105/352 - Pérdida de Entrenamiento: 0.5641, Precisión de Entrenamiento: 0.8042\n",
      "Iteración 6828 - Lote 140/352 - Pérdida de Entrenamiento: 0.5626, Precisión de Entrenamiento: 0.8046\n",
      "Iteración 6863 - Lote 175/352 - Pérdida de Entrenamiento: 0.5635, Precisión de Entrenamiento: 0.8045\n",
      "Iteración 6898 - Lote 210/352 - Pérdida de Entrenamiento: 0.5632, Precisión de Entrenamiento: 0.8053\n",
      "Iteración 6933 - Lote 245/352 - Pérdida de Entrenamiento: 0.5662, Precisión de Entrenamiento: 0.8040\n",
      "Iteración 6968 - Lote 280/352 - Pérdida de Entrenamiento: 0.5654, Precisión de Entrenamiento: 0.8041\n",
      "Iteración 7003 - Lote 315/352 - Pérdida de Entrenamiento: 0.5640, Precisión de Entrenamiento: 0.8054\n",
      "Iteración 7038 - Lote 350/352 - Pérdida de Entrenamiento: 0.5646, Precisión de Entrenamiento: 0.8051\n",
      "Tiempo de la época 20: 94.52 segundos\n",
      "Val loss: 0.7069, Val acc: 0.7652\n",
      "0.04\n",
      "Epoch 21/70\n",
      "Iteración 7075 - Lote 35/352 - Pérdida de Entrenamiento: 0.5490, Precisión de Entrenamiento: 0.8112\n",
      "Iteración 7110 - Lote 70/352 - Pérdida de Entrenamiento: 0.5575, Precisión de Entrenamiento: 0.8073\n",
      "Iteración 7145 - Lote 105/352 - Pérdida de Entrenamiento: 0.5492, Precisión de Entrenamiento: 0.8093\n",
      "Iteración 7180 - Lote 140/352 - Pérdida de Entrenamiento: 0.5493, Precisión de Entrenamiento: 0.8094\n",
      "Iteración 7215 - Lote 175/352 - Pérdida de Entrenamiento: 0.5533, Precisión de Entrenamiento: 0.8088\n",
      "Iteración 7250 - Lote 210/352 - Pérdida de Entrenamiento: 0.5469, Precisión de Entrenamiento: 0.8109\n",
      "Iteración 7285 - Lote 245/352 - Pérdida de Entrenamiento: 0.5476, Precisión de Entrenamiento: 0.8102\n",
      "Iteración 7320 - Lote 280/352 - Pérdida de Entrenamiento: 0.5460, Precisión de Entrenamiento: 0.8114\n",
      "Iteración 7355 - Lote 315/352 - Pérdida de Entrenamiento: 0.5438, Precisión de Entrenamiento: 0.8118\n",
      "Iteración 7390 - Lote 350/352 - Pérdida de Entrenamiento: 0.5452, Precisión de Entrenamiento: 0.8116\n",
      "Tiempo de la época 21: 94.31 segundos\n",
      "Val loss: 0.7165, Val acc: 0.7660\n",
      "0.04\n",
      "Epoch 22/70\n",
      "Iteración 7427 - Lote 35/352 - Pérdida de Entrenamiento: 0.5402, Precisión de Entrenamiento: 0.8125\n",
      "Iteración 7462 - Lote 70/352 - Pérdida de Entrenamiento: 0.5330, Precisión de Entrenamiento: 0.8129\n",
      "Iteración 7497 - Lote 105/352 - Pérdida de Entrenamiento: 0.5424, Precisión de Entrenamiento: 0.8118\n",
      "Iteración 7532 - Lote 140/352 - Pérdida de Entrenamiento: 0.5462, Precisión de Entrenamiento: 0.8109\n",
      "Iteración 7567 - Lote 175/352 - Pérdida de Entrenamiento: 0.5423, Precisión de Entrenamiento: 0.8120\n",
      "Iteración 7602 - Lote 210/352 - Pérdida de Entrenamiento: 0.5402, Precisión de Entrenamiento: 0.8134\n",
      "Iteración 7637 - Lote 245/352 - Pérdida de Entrenamiento: 0.5359, Precisión de Entrenamiento: 0.8152\n",
      "Iteración 7672 - Lote 280/352 - Pérdida de Entrenamiento: 0.5367, Precisión de Entrenamiento: 0.8150\n",
      "Iteración 7707 - Lote 315/352 - Pérdida de Entrenamiento: 0.5341, Precisión de Entrenamiento: 0.8159\n",
      "Iteración 7742 - Lote 350/352 - Pérdida de Entrenamiento: 0.5320, Precisión de Entrenamiento: 0.8162\n",
      "Tiempo de la época 22: 94.51 segundos\n",
      "Val loss: 0.5831, Val acc: 0.8114\n",
      "0.004\n",
      "Epoch 23/70\n",
      "Iteración 7779 - Lote 35/352 - Pérdida de Entrenamiento: 0.5003, Precisión de Entrenamiento: 0.8295\n",
      "Iteración 7814 - Lote 70/352 - Pérdida de Entrenamiento: 0.4894, Precisión de Entrenamiento: 0.8306\n",
      "Iteración 7849 - Lote 105/352 - Pérdida de Entrenamiento: 0.4647, Precisión de Entrenamiento: 0.8387\n",
      "Iteración 7884 - Lote 140/352 - Pérdida de Entrenamiento: 0.4584, Precisión de Entrenamiento: 0.8409\n",
      "Iteración 7919 - Lote 175/352 - Pérdida de Entrenamiento: 0.4569, Precisión de Entrenamiento: 0.8408\n",
      "Iteración 7954 - Lote 210/352 - Pérdida de Entrenamiento: 0.4607, Precisión de Entrenamiento: 0.8398\n",
      "Iteración 7989 - Lote 245/352 - Pérdida de Entrenamiento: 0.4589, Precisión de Entrenamiento: 0.8400\n",
      "Iteración 8024 - Lote 280/352 - Pérdida de Entrenamiento: 0.4589, Precisión de Entrenamiento: 0.8404\n",
      "Iteración 8059 - Lote 315/352 - Pérdida de Entrenamiento: 0.4551, Precisión de Entrenamiento: 0.8423\n",
      "Iteración 8094 - Lote 350/352 - Pérdida de Entrenamiento: 0.4529, Precisión de Entrenamiento: 0.8433\n",
      "Tiempo de la época 23: 93.65 segundos\n",
      "Val loss: 0.4409, Val acc: 0.8530\n",
      "Checkpoint guardado en CheckpointsResNet110_SD\\best_checkpoint_epoch_23.pth\n",
      "Checkpoint del mejor modelo guardado en la época 23\n",
      "0.004\n",
      "Epoch 24/70\n",
      "Iteración 8131 - Lote 35/352 - Pérdida de Entrenamiento: 0.4217, Precisión de Entrenamiento: 0.8493\n",
      "Iteración 8166 - Lote 70/352 - Pérdida de Entrenamiento: 0.4297, Precisión de Entrenamiento: 0.8490\n",
      "Iteración 8201 - Lote 105/352 - Pérdida de Entrenamiento: 0.4258, Precisión de Entrenamiento: 0.8504\n",
      "Iteración 8236 - Lote 140/352 - Pérdida de Entrenamiento: 0.4267, Precisión de Entrenamiento: 0.8505\n",
      "Iteración 8271 - Lote 175/352 - Pérdida de Entrenamiento: 0.4219, Precisión de Entrenamiento: 0.8524\n",
      "Iteración 8306 - Lote 210/352 - Pérdida de Entrenamiento: 0.4262, Precisión de Entrenamiento: 0.8511\n",
      "Iteración 8341 - Lote 245/352 - Pérdida de Entrenamiento: 0.4278, Precisión de Entrenamiento: 0.8509\n",
      "Iteración 8376 - Lote 280/352 - Pérdida de Entrenamiento: 0.4267, Precisión de Entrenamiento: 0.8515\n",
      "Iteración 8411 - Lote 315/352 - Pérdida de Entrenamiento: 0.4292, Precisión de Entrenamiento: 0.8507\n",
      "Iteración 8446 - Lote 350/352 - Pérdida de Entrenamiento: 0.4283, Precisión de Entrenamiento: 0.8506\n",
      "Tiempo de la época 24: 94.98 segundos\n",
      "Val loss: 0.4333, Val acc: 0.8518\n",
      "Checkpoint guardado en CheckpointsResNet110_SD\\best_checkpoint_epoch_24.pth\n",
      "Checkpoint del mejor modelo guardado en la época 24\n",
      "0.004\n",
      "Epoch 25/70\n",
      "Iteración 8483 - Lote 35/352 - Pérdida de Entrenamiento: 0.4141, Precisión de Entrenamiento: 0.8551\n",
      "Iteración 8518 - Lote 70/352 - Pérdida de Entrenamiento: 0.4258, Precisión de Entrenamiento: 0.8488\n",
      "Iteración 8553 - Lote 105/352 - Pérdida de Entrenamiento: 0.4319, Precisión de Entrenamiento: 0.8465\n",
      "Iteración 8588 - Lote 140/352 - Pérdida de Entrenamiento: 0.4287, Precisión de Entrenamiento: 0.8480\n",
      "Iteración 8623 - Lote 175/352 - Pérdida de Entrenamiento: 0.4264, Precisión de Entrenamiento: 0.8490\n",
      "Iteración 8658 - Lote 210/352 - Pérdida de Entrenamiento: 0.4246, Precisión de Entrenamiento: 0.8503\n",
      "Iteración 8693 - Lote 245/352 - Pérdida de Entrenamiento: 0.4243, Precisión de Entrenamiento: 0.8502\n",
      "Iteración 8728 - Lote 280/352 - Pérdida de Entrenamiento: 0.4266, Precisión de Entrenamiento: 0.8496\n",
      "Iteración 8763 - Lote 315/352 - Pérdida de Entrenamiento: 0.4259, Precisión de Entrenamiento: 0.8504\n",
      "Iteración 8798 - Lote 350/352 - Pérdida de Entrenamiento: 0.4269, Precisión de Entrenamiento: 0.8504\n",
      "Tiempo de la época 25: 93.86 segundos\n",
      "Val loss: 0.4286, Val acc: 0.8546\n",
      "Checkpoint guardado en CheckpointsResNet110_SD\\best_checkpoint_epoch_25.pth\n",
      "Checkpoint del mejor modelo guardado en la época 25\n",
      "0.004\n",
      "Epoch 26/70\n",
      "Iteración 8835 - Lote 35/352 - Pérdida de Entrenamiento: 0.4193, Precisión de Entrenamiento: 0.8536\n",
      "Iteración 8870 - Lote 70/352 - Pérdida de Entrenamiento: 0.4169, Precisión de Entrenamiento: 0.8547\n",
      "Iteración 8905 - Lote 105/352 - Pérdida de Entrenamiento: 0.4160, Precisión de Entrenamiento: 0.8567\n",
      "Iteración 8940 - Lote 140/352 - Pérdida de Entrenamiento: 0.4113, Precisión de Entrenamiento: 0.8569\n",
      "Iteración 8975 - Lote 175/352 - Pérdida de Entrenamiento: 0.4081, Precisión de Entrenamiento: 0.8578\n",
      "Iteración 9010 - Lote 210/352 - Pérdida de Entrenamiento: 0.4068, Precisión de Entrenamiento: 0.8580\n",
      "Iteración 9045 - Lote 245/352 - Pérdida de Entrenamiento: 0.4052, Precisión de Entrenamiento: 0.8583\n",
      "Iteración 9080 - Lote 280/352 - Pérdida de Entrenamiento: 0.4075, Precisión de Entrenamiento: 0.8580\n",
      "Iteración 9115 - Lote 315/352 - Pérdida de Entrenamiento: 0.4090, Precisión de Entrenamiento: 0.8575\n",
      "Iteración 9150 - Lote 350/352 - Pérdida de Entrenamiento: 0.4087, Precisión de Entrenamiento: 0.8575\n",
      "Tiempo de la época 26: 94.34 segundos\n",
      "Val loss: 0.4308, Val acc: 0.8602\n",
      "0.004\n",
      "Epoch 27/70\n",
      "Iteración 9187 - Lote 35/352 - Pérdida de Entrenamiento: 0.4076, Precisión de Entrenamiento: 0.8643\n",
      "Iteración 9222 - Lote 70/352 - Pérdida de Entrenamiento: 0.3892, Precisión de Entrenamiento: 0.8692\n",
      "Iteración 9257 - Lote 105/352 - Pérdida de Entrenamiento: 0.4010, Precisión de Entrenamiento: 0.8643\n",
      "Iteración 9292 - Lote 140/352 - Pérdida de Entrenamiento: 0.4052, Precisión de Entrenamiento: 0.8647\n",
      "Iteración 9327 - Lote 175/352 - Pérdida de Entrenamiento: 0.4059, Precisión de Entrenamiento: 0.8631\n",
      "Iteración 9362 - Lote 210/352 - Pérdida de Entrenamiento: 0.4042, Precisión de Entrenamiento: 0.8624\n",
      "Iteración 9397 - Lote 245/352 - Pérdida de Entrenamiento: 0.3984, Precisión de Entrenamiento: 0.8638\n",
      "Iteración 9432 - Lote 280/352 - Pérdida de Entrenamiento: 0.4014, Precisión de Entrenamiento: 0.8626\n",
      "Iteración 9467 - Lote 315/352 - Pérdida de Entrenamiento: 0.4034, Precisión de Entrenamiento: 0.8618\n",
      "Iteración 9502 - Lote 350/352 - Pérdida de Entrenamiento: 0.4050, Precisión de Entrenamiento: 0.8611\n",
      "Tiempo de la época 27: 93.77 segundos\n",
      "Val loss: 0.4269, Val acc: 0.8522\n",
      "Checkpoint guardado en CheckpointsResNet110_SD\\best_checkpoint_epoch_27.pth\n",
      "Checkpoint del mejor modelo guardado en la época 27\n",
      "0.004\n",
      "Epoch 28/70\n",
      "Iteración 9539 - Lote 35/352 - Pérdida de Entrenamiento: 0.3947, Precisión de Entrenamiento: 0.8636\n",
      "Iteración 9574 - Lote 70/352 - Pérdida de Entrenamiento: 0.3916, Precisión de Entrenamiento: 0.8654\n",
      "Iteración 9609 - Lote 105/352 - Pérdida de Entrenamiento: 0.3921, Precisión de Entrenamiento: 0.8635\n",
      "Iteración 9644 - Lote 140/352 - Pérdida de Entrenamiento: 0.3949, Precisión de Entrenamiento: 0.8605\n",
      "Iteración 9679 - Lote 175/352 - Pérdida de Entrenamiento: 0.3966, Precisión de Entrenamiento: 0.8604\n",
      "Iteración 9714 - Lote 210/352 - Pérdida de Entrenamiento: 0.3951, Precisión de Entrenamiento: 0.8617\n",
      "Iteración 9749 - Lote 245/352 - Pérdida de Entrenamiento: 0.3954, Precisión de Entrenamiento: 0.8616\n",
      "Iteración 9784 - Lote 280/352 - Pérdida de Entrenamiento: 0.3959, Precisión de Entrenamiento: 0.8618\n",
      "Iteración 9819 - Lote 315/352 - Pérdida de Entrenamiento: 0.3951, Precisión de Entrenamiento: 0.8627\n",
      "Iteración 9854 - Lote 350/352 - Pérdida de Entrenamiento: 0.3967, Precisión de Entrenamiento: 0.8620\n",
      "Tiempo de la época 28: 87.79 segundos\n",
      "Val loss: 0.4108, Val acc: 0.8580\n",
      "Checkpoint guardado en CheckpointsResNet110_SD\\best_checkpoint_epoch_28.pth\n",
      "Checkpoint del mejor modelo guardado en la época 28\n",
      "0.004\n",
      "Epoch 29/70\n",
      "Iteración 9891 - Lote 35/352 - Pérdida de Entrenamiento: 0.4084, Precisión de Entrenamiento: 0.8623\n",
      "Iteración 9926 - Lote 70/352 - Pérdida de Entrenamiento: 0.4087, Precisión de Entrenamiento: 0.8577\n",
      "Iteración 9961 - Lote 105/352 - Pérdida de Entrenamiento: 0.3991, Precisión de Entrenamiento: 0.8621\n",
      "Iteración 9996 - Lote 140/352 - Pérdida de Entrenamiento: 0.4002, Precisión de Entrenamiento: 0.8631\n",
      "Iteración 10031 - Lote 175/352 - Pérdida de Entrenamiento: 0.3962, Precisión de Entrenamiento: 0.8654\n",
      "Iteración 10066 - Lote 210/352 - Pérdida de Entrenamiento: 0.3988, Precisión de Entrenamiento: 0.8645\n",
      "Iteración 10101 - Lote 245/352 - Pérdida de Entrenamiento: 0.3964, Precisión de Entrenamiento: 0.8655\n",
      "Iteración 10136 - Lote 280/352 - Pérdida de Entrenamiento: 0.3960, Precisión de Entrenamiento: 0.8655\n",
      "Iteración 10171 - Lote 315/352 - Pérdida de Entrenamiento: 0.3964, Precisión de Entrenamiento: 0.8651\n",
      "Iteración 10206 - Lote 350/352 - Pérdida de Entrenamiento: 0.3971, Precisión de Entrenamiento: 0.8649\n",
      "Tiempo de la época 29: 86.76 segundos\n",
      "Val loss: 0.4174, Val acc: 0.8602\n",
      "0.004\n",
      "Epoch 30/70\n",
      "Iteración 10243 - Lote 35/352 - Pérdida de Entrenamiento: 0.4085, Precisión de Entrenamiento: 0.8592\n",
      "Iteración 10278 - Lote 70/352 - Pérdida de Entrenamiento: 0.3879, Precisión de Entrenamiento: 0.8644\n",
      "Iteración 10313 - Lote 105/352 - Pérdida de Entrenamiento: 0.3951, Precisión de Entrenamiento: 0.8626\n",
      "Iteración 10348 - Lote 140/352 - Pérdida de Entrenamiento: 0.3921, Precisión de Entrenamiento: 0.8628\n",
      "Iteración 10383 - Lote 175/352 - Pérdida de Entrenamiento: 0.3912, Precisión de Entrenamiento: 0.8624\n",
      "Iteración 10418 - Lote 210/352 - Pérdida de Entrenamiento: 0.3919, Precisión de Entrenamiento: 0.8630\n",
      "Iteración 10453 - Lote 245/352 - Pérdida de Entrenamiento: 0.3895, Precisión de Entrenamiento: 0.8639\n",
      "Iteración 10488 - Lote 280/352 - Pérdida de Entrenamiento: 0.3891, Precisión de Entrenamiento: 0.8646\n",
      "Iteración 10523 - Lote 315/352 - Pérdida de Entrenamiento: 0.3899, Precisión de Entrenamiento: 0.8641\n",
      "Iteración 10558 - Lote 350/352 - Pérdida de Entrenamiento: 0.3920, Precisión de Entrenamiento: 0.8634\n",
      "Tiempo de la época 30: 87.05 segundos\n",
      "Val loss: 0.4130, Val acc: 0.8610\n",
      "0.004\n",
      "Epoch 31/70\n",
      "Iteración 10595 - Lote 35/352 - Pérdida de Entrenamiento: 0.3982, Precisión de Entrenamiento: 0.8596\n",
      "Iteración 10630 - Lote 70/352 - Pérdida de Entrenamiento: 0.4094, Precisión de Entrenamiento: 0.8585\n",
      "Iteración 10665 - Lote 105/352 - Pérdida de Entrenamiento: 0.4053, Precisión de Entrenamiento: 0.8600\n",
      "Iteración 10700 - Lote 140/352 - Pérdida de Entrenamiento: 0.3976, Precisión de Entrenamiento: 0.8634\n",
      "Iteración 10735 - Lote 175/352 - Pérdida de Entrenamiento: 0.3931, Precisión de Entrenamiento: 0.8647\n",
      "Iteración 10770 - Lote 210/352 - Pérdida de Entrenamiento: 0.3940, Precisión de Entrenamiento: 0.8644\n",
      "Iteración 10805 - Lote 245/352 - Pérdida de Entrenamiento: 0.3949, Precisión de Entrenamiento: 0.8641\n",
      "Iteración 10840 - Lote 280/352 - Pérdida de Entrenamiento: 0.3962, Precisión de Entrenamiento: 0.8636\n",
      "Iteración 10875 - Lote 315/352 - Pérdida de Entrenamiento: 0.3963, Precisión de Entrenamiento: 0.8635\n",
      "Iteración 10910 - Lote 350/352 - Pérdida de Entrenamiento: 0.3933, Precisión de Entrenamiento: 0.8644\n",
      "Tiempo de la época 31: 86.49 segundos\n",
      "Val loss: 0.4114, Val acc: 0.8602\n",
      "0.004\n",
      "Epoch 32/70\n",
      "Iteración 10947 - Lote 35/352 - Pérdida de Entrenamiento: 0.3600, Precisión de Entrenamiento: 0.8739\n",
      "Iteración 10982 - Lote 70/352 - Pérdida de Entrenamiento: 0.3881, Precisión de Entrenamiento: 0.8670\n",
      "Iteración 11017 - Lote 105/352 - Pérdida de Entrenamiento: 0.3829, Precisión de Entrenamiento: 0.8678\n",
      "Iteración 11052 - Lote 140/352 - Pérdida de Entrenamiento: 0.3804, Precisión de Entrenamiento: 0.8690\n",
      "Iteración 11087 - Lote 175/352 - Pérdida de Entrenamiento: 0.3813, Precisión de Entrenamiento: 0.8696\n",
      "Iteración 11122 - Lote 210/352 - Pérdida de Entrenamiento: 0.3844, Precisión de Entrenamiento: 0.8679\n",
      "Iteración 11157 - Lote 245/352 - Pérdida de Entrenamiento: 0.3852, Precisión de Entrenamiento: 0.8677\n",
      "Iteración 11192 - Lote 280/352 - Pérdida de Entrenamiento: 0.3868, Precisión de Entrenamiento: 0.8664\n",
      "Iteración 11227 - Lote 315/352 - Pérdida de Entrenamiento: 0.3861, Precisión de Entrenamiento: 0.8673\n",
      "Iteración 11262 - Lote 350/352 - Pérdida de Entrenamiento: 0.3861, Precisión de Entrenamiento: 0.8673\n",
      "Tiempo de la época 32: 86.88 segundos\n",
      "Val loss: 0.4035, Val acc: 0.8622\n",
      "Checkpoint guardado en CheckpointsResNet110_SD\\best_checkpoint_epoch_32.pth\n",
      "Checkpoint del mejor modelo guardado en la época 32\n",
      "0.004\n",
      "Epoch 33/70\n",
      "Iteración 11299 - Lote 35/352 - Pérdida de Entrenamiento: 0.3971, Precisión de Entrenamiento: 0.8603\n",
      "Iteración 11334 - Lote 70/352 - Pérdida de Entrenamiento: 0.3944, Precisión de Entrenamiento: 0.8626\n",
      "Iteración 11369 - Lote 105/352 - Pérdida de Entrenamiento: 0.3975, Precisión de Entrenamiento: 0.8605\n",
      "Iteración 11404 - Lote 140/352 - Pérdida de Entrenamiento: 0.3937, Precisión de Entrenamiento: 0.8622\n",
      "Iteración 11439 - Lote 175/352 - Pérdida de Entrenamiento: 0.3923, Precisión de Entrenamiento: 0.8621\n",
      "Iteración 11474 - Lote 210/352 - Pérdida de Entrenamiento: 0.3882, Precisión de Entrenamiento: 0.8636\n",
      "Iteración 11509 - Lote 245/352 - Pérdida de Entrenamiento: 0.3872, Precisión de Entrenamiento: 0.8642\n",
      "Iteración 11544 - Lote 280/352 - Pérdida de Entrenamiento: 0.3847, Precisión de Entrenamiento: 0.8652\n",
      "Iteración 11579 - Lote 315/352 - Pérdida de Entrenamiento: 0.3844, Precisión de Entrenamiento: 0.8655\n",
      "Iteración 11614 - Lote 350/352 - Pérdida de Entrenamiento: 0.3848, Precisión de Entrenamiento: 0.8658\n",
      "Tiempo de la época 33: 86.61 segundos\n",
      "Val loss: 0.4098, Val acc: 0.8620\n",
      "0.004\n",
      "Epoch 34/70\n",
      "Iteración 11651 - Lote 35/352 - Pérdida de Entrenamiento: 0.3710, Precisión de Entrenamiento: 0.8670\n",
      "Iteración 11686 - Lote 70/352 - Pérdida de Entrenamiento: 0.3751, Precisión de Entrenamiento: 0.8690\n",
      "Iteración 11721 - Lote 105/352 - Pérdida de Entrenamiento: 0.3781, Precisión de Entrenamiento: 0.8688\n",
      "Iteración 11756 - Lote 140/352 - Pérdida de Entrenamiento: 0.3779, Precisión de Entrenamiento: 0.8684\n",
      "Iteración 11791 - Lote 175/352 - Pérdida de Entrenamiento: 0.3800, Precisión de Entrenamiento: 0.8671\n",
      "Iteración 11826 - Lote 210/352 - Pérdida de Entrenamiento: 0.3811, Precisión de Entrenamiento: 0.8661\n",
      "Iteración 11861 - Lote 245/352 - Pérdida de Entrenamiento: 0.3804, Precisión de Entrenamiento: 0.8666\n",
      "Iteración 11896 - Lote 280/352 - Pérdida de Entrenamiento: 0.3806, Precisión de Entrenamiento: 0.8668\n",
      "Iteración 11931 - Lote 315/352 - Pérdida de Entrenamiento: 0.3813, Precisión de Entrenamiento: 0.8667\n",
      "Iteración 11966 - Lote 350/352 - Pérdida de Entrenamiento: 0.3813, Precisión de Entrenamiento: 0.8673\n",
      "Tiempo de la época 34: 86.81 segundos\n",
      "Val loss: 0.4123, Val acc: 0.8652\n",
      "0.004\n",
      "Epoch 35/70\n",
      "Iteración 12003 - Lote 35/352 - Pérdida de Entrenamiento: 0.3683, Precisión de Entrenamiento: 0.8741\n",
      "Iteración 12038 - Lote 70/352 - Pérdida de Entrenamiento: 0.3713, Precisión de Entrenamiento: 0.8746\n",
      "Iteración 12073 - Lote 105/352 - Pérdida de Entrenamiento: 0.3723, Precisión de Entrenamiento: 0.8725\n",
      "Iteración 12108 - Lote 140/352 - Pérdida de Entrenamiento: 0.3744, Precisión de Entrenamiento: 0.8717\n",
      "Iteración 12143 - Lote 175/352 - Pérdida de Entrenamiento: 0.3768, Precisión de Entrenamiento: 0.8712\n",
      "Iteración 12178 - Lote 210/352 - Pérdida de Entrenamiento: 0.3764, Precisión de Entrenamiento: 0.8701\n",
      "Iteración 12213 - Lote 245/352 - Pérdida de Entrenamiento: 0.3745, Precisión de Entrenamiento: 0.8714\n",
      "Iteración 12248 - Lote 280/352 - Pérdida de Entrenamiento: 0.3748, Precisión de Entrenamiento: 0.8714\n",
      "Iteración 12283 - Lote 315/352 - Pérdida de Entrenamiento: 0.3770, Precisión de Entrenamiento: 0.8700\n",
      "Iteración 12318 - Lote 350/352 - Pérdida de Entrenamiento: 0.3791, Precisión de Entrenamiento: 0.8695\n",
      "Tiempo de la época 35: 86.21 segundos\n",
      "Val loss: 0.3976, Val acc: 0.8686\n",
      "Checkpoint guardado en CheckpointsResNet110_SD\\best_checkpoint_epoch_35.pth\n",
      "Checkpoint del mejor modelo guardado en la época 35\n",
      "0.004\n",
      "Epoch 36/70\n",
      "Iteración 12355 - Lote 35/352 - Pérdida de Entrenamiento: 0.3678, Precisión de Entrenamiento: 0.8739\n",
      "Iteración 12390 - Lote 70/352 - Pérdida de Entrenamiento: 0.3820, Precisión de Entrenamiento: 0.8648\n",
      "Iteración 12425 - Lote 105/352 - Pérdida de Entrenamiento: 0.3819, Precisión de Entrenamiento: 0.8671\n",
      "Iteración 12460 - Lote 140/352 - Pérdida de Entrenamiento: 0.3787, Precisión de Entrenamiento: 0.8685\n",
      "Iteración 12495 - Lote 175/352 - Pérdida de Entrenamiento: 0.3767, Precisión de Entrenamiento: 0.8693\n",
      "Iteración 12530 - Lote 210/352 - Pérdida de Entrenamiento: 0.3798, Precisión de Entrenamiento: 0.8682\n",
      "Iteración 12565 - Lote 245/352 - Pérdida de Entrenamiento: 0.3788, Precisión de Entrenamiento: 0.8681\n",
      "Iteración 12600 - Lote 280/352 - Pérdida de Entrenamiento: 0.3800, Precisión de Entrenamiento: 0.8674\n",
      "Iteración 12635 - Lote 315/352 - Pérdida de Entrenamiento: 0.3771, Precisión de Entrenamiento: 0.8683\n",
      "Iteración 12670 - Lote 350/352 - Pérdida de Entrenamiento: 0.3794, Precisión de Entrenamiento: 0.8682\n",
      "Tiempo de la época 36: 86.52 segundos\n",
      "Val loss: 0.4006, Val acc: 0.8652\n",
      "0.004\n",
      "Epoch 37/70\n",
      "Iteración 12707 - Lote 35/352 - Pérdida de Entrenamiento: 0.3925, Precisión de Entrenamiento: 0.8688\n",
      "Iteración 12742 - Lote 70/352 - Pérdida de Entrenamiento: 0.3813, Precisión de Entrenamiento: 0.8717\n",
      "Iteración 12777 - Lote 105/352 - Pérdida de Entrenamiento: 0.3745, Precisión de Entrenamiento: 0.8722\n",
      "Iteración 12812 - Lote 140/352 - Pérdida de Entrenamiento: 0.3738, Precisión de Entrenamiento: 0.8723\n",
      "Iteración 12847 - Lote 175/352 - Pérdida de Entrenamiento: 0.3718, Precisión de Entrenamiento: 0.8731\n",
      "Iteración 12882 - Lote 210/352 - Pérdida de Entrenamiento: 0.3707, Precisión de Entrenamiento: 0.8735\n",
      "Iteración 12917 - Lote 245/352 - Pérdida de Entrenamiento: 0.3747, Precisión de Entrenamiento: 0.8721\n",
      "Iteración 12952 - Lote 280/352 - Pérdida de Entrenamiento: 0.3748, Precisión de Entrenamiento: 0.8728\n",
      "Iteración 12987 - Lote 315/352 - Pérdida de Entrenamiento: 0.3730, Precisión de Entrenamiento: 0.8731\n",
      "Iteración 13022 - Lote 350/352 - Pérdida de Entrenamiento: 0.3716, Precisión de Entrenamiento: 0.8728\n",
      "Tiempo de la época 37: 86.45 segundos\n",
      "Val loss: 0.4072, Val acc: 0.8668\n",
      "0.004\n",
      "Epoch 38/70\n",
      "Iteración 13059 - Lote 35/352 - Pérdida de Entrenamiento: 0.3515, Precisión de Entrenamiento: 0.8772\n",
      "Iteración 13094 - Lote 70/352 - Pérdida de Entrenamiento: 0.3572, Precisión de Entrenamiento: 0.8758\n",
      "Iteración 13129 - Lote 105/352 - Pérdida de Entrenamiento: 0.3626, Precisión de Entrenamiento: 0.8743\n",
      "Iteración 13164 - Lote 140/352 - Pérdida de Entrenamiento: 0.3644, Precisión de Entrenamiento: 0.8729\n",
      "Iteración 13199 - Lote 175/352 - Pérdida de Entrenamiento: 0.3643, Precisión de Entrenamiento: 0.8725\n",
      "Iteración 13234 - Lote 210/352 - Pérdida de Entrenamiento: 0.3663, Precisión de Entrenamiento: 0.8722\n",
      "Iteración 13269 - Lote 245/352 - Pérdida de Entrenamiento: 0.3682, Precisión de Entrenamiento: 0.8719\n",
      "Iteración 13304 - Lote 280/352 - Pérdida de Entrenamiento: 0.3709, Precisión de Entrenamiento: 0.8710\n",
      "Iteración 13339 - Lote 315/352 - Pérdida de Entrenamiento: 0.3704, Precisión de Entrenamiento: 0.8713\n",
      "Iteración 13374 - Lote 350/352 - Pérdida de Entrenamiento: 0.3692, Precisión de Entrenamiento: 0.8720\n",
      "Tiempo de la época 38: 86.49 segundos\n",
      "Val loss: 0.3961, Val acc: 0.8676\n",
      "Checkpoint guardado en CheckpointsResNet110_SD\\best_checkpoint_epoch_38.pth\n",
      "Checkpoint del mejor modelo guardado en la época 38\n",
      "0.004\n",
      "Epoch 39/70\n",
      "Iteración 13411 - Lote 35/352 - Pérdida de Entrenamiento: 0.3676, Precisión de Entrenamiento: 0.8743\n",
      "Iteración 13446 - Lote 70/352 - Pérdida de Entrenamiento: 0.3657, Precisión de Entrenamiento: 0.8734\n",
      "Iteración 13481 - Lote 105/352 - Pérdida de Entrenamiento: 0.3638, Precisión de Entrenamiento: 0.8743\n",
      "Iteración 13516 - Lote 140/352 - Pérdida de Entrenamiento: 0.3642, Precisión de Entrenamiento: 0.8742\n",
      "Iteración 13551 - Lote 175/352 - Pérdida de Entrenamiento: 0.3645, Precisión de Entrenamiento: 0.8731\n",
      "Iteración 13586 - Lote 210/352 - Pérdida de Entrenamiento: 0.3632, Precisión de Entrenamiento: 0.8744\n",
      "Iteración 13621 - Lote 245/352 - Pérdida de Entrenamiento: 0.3636, Precisión de Entrenamiento: 0.8731\n",
      "Iteración 13656 - Lote 280/352 - Pérdida de Entrenamiento: 0.3656, Precisión de Entrenamiento: 0.8722\n",
      "Iteración 13691 - Lote 315/352 - Pérdida de Entrenamiento: 0.3654, Precisión de Entrenamiento: 0.8725\n",
      "Iteración 13726 - Lote 350/352 - Pérdida de Entrenamiento: 0.3641, Precisión de Entrenamiento: 0.8731\n",
      "Tiempo de la época 39: 86.97 segundos\n",
      "Val loss: 0.4015, Val acc: 0.8674\n",
      "0.004\n",
      "Epoch 40/70\n",
      "Iteración 13763 - Lote 35/352 - Pérdida de Entrenamiento: 0.3627, Precisión de Entrenamiento: 0.8806\n",
      "Iteración 13798 - Lote 70/352 - Pérdida de Entrenamiento: 0.3693, Precisión de Entrenamiento: 0.8746\n",
      "Iteración 13833 - Lote 105/352 - Pérdida de Entrenamiento: 0.3640, Precisión de Entrenamiento: 0.8754\n",
      "Iteración 13868 - Lote 140/352 - Pérdida de Entrenamiento: 0.3699, Precisión de Entrenamiento: 0.8730\n",
      "Iteración 13903 - Lote 175/352 - Pérdida de Entrenamiento: 0.3704, Precisión de Entrenamiento: 0.8720\n",
      "Iteración 13938 - Lote 210/352 - Pérdida de Entrenamiento: 0.3664, Precisión de Entrenamiento: 0.8730\n",
      "Iteración 13973 - Lote 245/352 - Pérdida de Entrenamiento: 0.3649, Precisión de Entrenamiento: 0.8736\n",
      "Iteración 14008 - Lote 280/352 - Pérdida de Entrenamiento: 0.3641, Precisión de Entrenamiento: 0.8739\n",
      "Iteración 14043 - Lote 315/352 - Pérdida de Entrenamiento: 0.3632, Precisión de Entrenamiento: 0.8736\n",
      "Iteración 14078 - Lote 350/352 - Pérdida de Entrenamiento: 0.3617, Precisión de Entrenamiento: 0.8743\n",
      "Tiempo de la época 40: 86.92 segundos\n",
      "Val loss: 0.3943, Val acc: 0.8678\n",
      "Checkpoint guardado en CheckpointsResNet110_SD\\best_checkpoint_epoch_40.pth\n",
      "Checkpoint del mejor modelo guardado en la época 40\n",
      "0.004\n",
      "Epoch 41/70\n",
      "Iteración 14115 - Lote 35/352 - Pérdida de Entrenamiento: 0.3830, Precisión de Entrenamiento: 0.8665\n",
      "Iteración 14150 - Lote 70/352 - Pérdida de Entrenamiento: 0.3695, Precisión de Entrenamiento: 0.8710\n",
      "Iteración 14185 - Lote 105/352 - Pérdida de Entrenamiento: 0.3683, Precisión de Entrenamiento: 0.8727\n",
      "Iteración 14220 - Lote 140/352 - Pérdida de Entrenamiento: 0.3717, Precisión de Entrenamiento: 0.8715\n",
      "Iteración 14255 - Lote 175/352 - Pérdida de Entrenamiento: 0.3734, Precisión de Entrenamiento: 0.8706\n",
      "Iteración 14290 - Lote 210/352 - Pérdida de Entrenamiento: 0.3725, Precisión de Entrenamiento: 0.8707\n",
      "Iteración 14325 - Lote 245/352 - Pérdida de Entrenamiento: 0.3683, Precisión de Entrenamiento: 0.8721\n",
      "Iteración 14360 - Lote 280/352 - Pérdida de Entrenamiento: 0.3672, Precisión de Entrenamiento: 0.8722\n",
      "Iteración 14395 - Lote 315/352 - Pérdida de Entrenamiento: 0.3657, Precisión de Entrenamiento: 0.8727\n",
      "Iteración 14430 - Lote 350/352 - Pérdida de Entrenamiento: 0.3648, Precisión de Entrenamiento: 0.8732\n",
      "Tiempo de la época 41: 86.91 segundos\n",
      "Val loss: 0.3897, Val acc: 0.8710\n",
      "Checkpoint guardado en CheckpointsResNet110_SD\\best_checkpoint_epoch_41.pth\n",
      "Checkpoint del mejor modelo guardado en la época 41\n",
      "0.004\n",
      "Epoch 42/70\n",
      "Iteración 14467 - Lote 35/352 - Pérdida de Entrenamiento: 0.3774, Precisión de Entrenamiento: 0.8703\n",
      "Iteración 14502 - Lote 70/352 - Pérdida de Entrenamiento: 0.3683, Precisión de Entrenamiento: 0.8727\n",
      "Iteración 14537 - Lote 105/352 - Pérdida de Entrenamiento: 0.3664, Precisión de Entrenamiento: 0.8737\n",
      "Iteración 14572 - Lote 140/352 - Pérdida de Entrenamiento: 0.3674, Precisión de Entrenamiento: 0.8722\n",
      "Iteración 14607 - Lote 175/352 - Pérdida de Entrenamiento: 0.3672, Precisión de Entrenamiento: 0.8730\n",
      "Iteración 14642 - Lote 210/352 - Pérdida de Entrenamiento: 0.3642, Precisión de Entrenamiento: 0.8741\n",
      "Iteración 14677 - Lote 245/352 - Pérdida de Entrenamiento: 0.3625, Precisión de Entrenamiento: 0.8751\n",
      "Iteración 14712 - Lote 280/352 - Pérdida de Entrenamiento: 0.3635, Precisión de Entrenamiento: 0.8749\n",
      "Iteración 14747 - Lote 315/352 - Pérdida de Entrenamiento: 0.3607, Precisión de Entrenamiento: 0.8758\n",
      "Iteración 14782 - Lote 350/352 - Pérdida de Entrenamiento: 0.3603, Precisión de Entrenamiento: 0.8758\n",
      "Tiempo de la época 42: 86.64 segundos\n",
      "Val loss: 0.3957, Val acc: 0.8708\n",
      "0.004\n",
      "Epoch 43/70\n",
      "Iteración 14819 - Lote 35/352 - Pérdida de Entrenamiento: 0.3465, Precisión de Entrenamiento: 0.8815\n",
      "Iteración 14854 - Lote 70/352 - Pérdida de Entrenamiento: 0.3447, Precisión de Entrenamiento: 0.8834\n",
      "Iteración 14889 - Lote 105/352 - Pérdida de Entrenamiento: 0.3465, Precisión de Entrenamiento: 0.8831\n",
      "Iteración 14924 - Lote 140/352 - Pérdida de Entrenamiento: 0.3530, Precisión de Entrenamiento: 0.8811\n",
      "Iteración 14959 - Lote 175/352 - Pérdida de Entrenamiento: 0.3498, Precisión de Entrenamiento: 0.8809\n",
      "Iteración 14994 - Lote 210/352 - Pérdida de Entrenamiento: 0.3546, Precisión de Entrenamiento: 0.8793\n",
      "Iteración 15029 - Lote 245/352 - Pérdida de Entrenamiento: 0.3517, Precisión de Entrenamiento: 0.8796\n",
      "Iteración 15064 - Lote 280/352 - Pérdida de Entrenamiento: 0.3549, Precisión de Entrenamiento: 0.8781\n",
      "Iteración 15099 - Lote 315/352 - Pérdida de Entrenamiento: 0.3556, Precisión de Entrenamiento: 0.8776\n",
      "Iteración 15134 - Lote 350/352 - Pérdida de Entrenamiento: 0.3556, Precisión de Entrenamiento: 0.8774\n",
      "Tiempo de la época 43: 87.17 segundos\n",
      "Val loss: 0.3874, Val acc: 0.8728\n",
      "Checkpoint guardado en CheckpointsResNet110_SD\\best_checkpoint_epoch_43.pth\n",
      "Checkpoint del mejor modelo guardado en la época 43\n",
      "0.004\n",
      "Epoch 44/70\n",
      "Iteración 15171 - Lote 35/352 - Pérdida de Entrenamiento: 0.3524, Precisión de Entrenamiento: 0.8757\n",
      "Iteración 15206 - Lote 70/352 - Pérdida de Entrenamiento: 0.3673, Precisión de Entrenamiento: 0.8705\n",
      "Iteración 15241 - Lote 105/352 - Pérdida de Entrenamiento: 0.3642, Precisión de Entrenamiento: 0.8727\n",
      "Iteración 15276 - Lote 140/352 - Pérdida de Entrenamiento: 0.3631, Precisión de Entrenamiento: 0.8735\n",
      "Iteración 15311 - Lote 175/352 - Pérdida de Entrenamiento: 0.3596, Precisión de Entrenamiento: 0.8745\n",
      "Iteración 15346 - Lote 210/352 - Pérdida de Entrenamiento: 0.3588, Precisión de Entrenamiento: 0.8747\n",
      "Iteración 15381 - Lote 245/352 - Pérdida de Entrenamiento: 0.3559, Precisión de Entrenamiento: 0.8756\n",
      "Iteración 15416 - Lote 280/352 - Pérdida de Entrenamiento: 0.3541, Precisión de Entrenamiento: 0.8765\n",
      "Iteración 15451 - Lote 315/352 - Pérdida de Entrenamiento: 0.3530, Precisión de Entrenamiento: 0.8770\n",
      "Iteración 15486 - Lote 350/352 - Pérdida de Entrenamiento: 0.3534, Precisión de Entrenamiento: 0.8769\n",
      "Tiempo de la época 44: 86.45 segundos\n",
      "Val loss: 0.4114, Val acc: 0.8698\n",
      "0.004\n",
      "Epoch 45/70\n",
      "Iteración 15523 - Lote 35/352 - Pérdida de Entrenamiento: 0.3359, Precisión de Entrenamiento: 0.8839\n",
      "Iteración 15558 - Lote 70/352 - Pérdida de Entrenamiento: 0.3524, Precisión de Entrenamiento: 0.8792\n",
      "Iteración 15593 - Lote 105/352 - Pérdida de Entrenamiento: 0.3470, Precisión de Entrenamiento: 0.8811\n",
      "Iteración 15628 - Lote 140/352 - Pérdida de Entrenamiento: 0.3548, Precisión de Entrenamiento: 0.8781\n",
      "Iteración 15663 - Lote 175/352 - Pérdida de Entrenamiento: 0.3503, Precisión de Entrenamiento: 0.8796\n",
      "Iteración 15698 - Lote 210/352 - Pérdida de Entrenamiento: 0.3508, Precisión de Entrenamiento: 0.8797\n",
      "Iteración 15733 - Lote 245/352 - Pérdida de Entrenamiento: 0.3491, Precisión de Entrenamiento: 0.8798\n",
      "Iteración 15768 - Lote 280/352 - Pérdida de Entrenamiento: 0.3483, Precisión de Entrenamiento: 0.8806\n",
      "Iteración 15803 - Lote 315/352 - Pérdida de Entrenamiento: 0.3483, Precisión de Entrenamiento: 0.8810\n",
      "Iteración 15838 - Lote 350/352 - Pérdida de Entrenamiento: 0.3513, Precisión de Entrenamiento: 0.8802\n",
      "Tiempo de la época 45: 86.36 segundos\n",
      "Val loss: 0.3870, Val acc: 0.8734\n",
      "Checkpoint guardado en CheckpointsResNet110_SD\\best_checkpoint_epoch_45.pth\n",
      "Checkpoint del mejor modelo guardado en la época 45\n",
      "0.004\n",
      "Epoch 46/70\n",
      "Iteración 15875 - Lote 35/352 - Pérdida de Entrenamiento: 0.3325, Precisión de Entrenamiento: 0.8855\n",
      "Iteración 15910 - Lote 70/352 - Pérdida de Entrenamiento: 0.3420, Precisión de Entrenamiento: 0.8802\n",
      "Iteración 15945 - Lote 105/352 - Pérdida de Entrenamiento: 0.3474, Precisión de Entrenamiento: 0.8785\n",
      "Iteración 15980 - Lote 140/352 - Pérdida de Entrenamiento: 0.3475, Precisión de Entrenamiento: 0.8786\n",
      "Iteración 16015 - Lote 175/352 - Pérdida de Entrenamiento: 0.3464, Precisión de Entrenamiento: 0.8800\n",
      "Iteración 16050 - Lote 210/352 - Pérdida de Entrenamiento: 0.3428, Precisión de Entrenamiento: 0.8807\n",
      "Iteración 16085 - Lote 245/352 - Pérdida de Entrenamiento: 0.3456, Precisión de Entrenamiento: 0.8804\n",
      "Iteración 16120 - Lote 280/352 - Pérdida de Entrenamiento: 0.3457, Precisión de Entrenamiento: 0.8805\n",
      "Iteración 16155 - Lote 315/352 - Pérdida de Entrenamiento: 0.3459, Precisión de Entrenamiento: 0.8804\n",
      "Iteración 16190 - Lote 350/352 - Pérdida de Entrenamiento: 0.3467, Precisión de Entrenamiento: 0.8797\n",
      "Tiempo de la época 46: 86.75 segundos\n",
      "Val loss: 0.4088, Val acc: 0.8644\n",
      "0.004\n",
      "Epoch 47/70\n",
      "Iteración 16227 - Lote 35/352 - Pérdida de Entrenamiento: 0.3554, Precisión de Entrenamiento: 0.8788\n",
      "Iteración 16262 - Lote 70/352 - Pérdida de Entrenamiento: 0.3532, Precisión de Entrenamiento: 0.8783\n",
      "Iteración 16297 - Lote 105/352 - Pérdida de Entrenamiento: 0.3524, Precisión de Entrenamiento: 0.8775\n",
      "Iteración 16332 - Lote 140/352 - Pérdida de Entrenamiento: 0.3515, Precisión de Entrenamiento: 0.8773\n",
      "Iteración 16367 - Lote 175/352 - Pérdida de Entrenamiento: 0.3476, Precisión de Entrenamiento: 0.8796\n",
      "Iteración 16402 - Lote 210/352 - Pérdida de Entrenamiento: 0.3469, Precisión de Entrenamiento: 0.8791\n",
      "Iteración 16437 - Lote 245/352 - Pérdida de Entrenamiento: 0.3498, Precisión de Entrenamiento: 0.8781\n",
      "Iteración 16472 - Lote 280/352 - Pérdida de Entrenamiento: 0.3487, Precisión de Entrenamiento: 0.8790\n",
      "Iteración 16507 - Lote 315/352 - Pérdida de Entrenamiento: 0.3470, Precisión de Entrenamiento: 0.8789\n",
      "Iteración 16542 - Lote 350/352 - Pérdida de Entrenamiento: 0.3472, Precisión de Entrenamiento: 0.8793\n",
      "Tiempo de la época 47: 86.40 segundos\n",
      "Val loss: 0.4005, Val acc: 0.8684\n",
      "0.004\n",
      "Epoch 48/70\n",
      "Iteración 16579 - Lote 35/352 - Pérdida de Entrenamiento: 0.3155, Precisión de Entrenamiento: 0.8871\n",
      "Iteración 16614 - Lote 70/352 - Pérdida de Entrenamiento: 0.3396, Precisión de Entrenamiento: 0.8794\n",
      "Iteración 16649 - Lote 105/352 - Pérdida de Entrenamiento: 0.3469, Precisión de Entrenamiento: 0.8785\n",
      "Iteración 16684 - Lote 140/352 - Pérdida de Entrenamiento: 0.3459, Precisión de Entrenamiento: 0.8783\n",
      "Iteración 16719 - Lote 175/352 - Pérdida de Entrenamiento: 0.3459, Precisión de Entrenamiento: 0.8786\n",
      "Iteración 16754 - Lote 210/352 - Pérdida de Entrenamiento: 0.3428, Precisión de Entrenamiento: 0.8799\n",
      "Iteración 16789 - Lote 245/352 - Pérdida de Entrenamiento: 0.3448, Precisión de Entrenamiento: 0.8794\n",
      "Iteración 16824 - Lote 280/352 - Pérdida de Entrenamiento: 0.3464, Precisión de Entrenamiento: 0.8782\n",
      "Iteración 16859 - Lote 315/352 - Pérdida de Entrenamiento: 0.3446, Precisión de Entrenamiento: 0.8791\n",
      "Iteración 16894 - Lote 350/352 - Pérdida de Entrenamiento: 0.3439, Precisión de Entrenamiento: 0.8796\n",
      "Tiempo de la época 48: 86.56 segundos\n",
      "Val loss: 0.3974, Val acc: 0.8722\n",
      "0.004\n",
      "Epoch 49/70\n",
      "Iteración 16931 - Lote 35/352 - Pérdida de Entrenamiento: 0.3298, Precisión de Entrenamiento: 0.8897\n",
      "Iteración 16966 - Lote 70/352 - Pérdida de Entrenamiento: 0.3315, Precisión de Entrenamiento: 0.8874\n",
      "Iteración 17001 - Lote 105/352 - Pérdida de Entrenamiento: 0.3377, Precisión de Entrenamiento: 0.8847\n",
      "Iteración 17036 - Lote 140/352 - Pérdida de Entrenamiento: 0.3384, Precisión de Entrenamiento: 0.8845\n",
      "Iteración 17071 - Lote 175/352 - Pérdida de Entrenamiento: 0.3397, Precisión de Entrenamiento: 0.8827\n",
      "Iteración 17106 - Lote 210/352 - Pérdida de Entrenamiento: 0.3394, Precisión de Entrenamiento: 0.8832\n",
      "Iteración 17141 - Lote 245/352 - Pérdida de Entrenamiento: 0.3401, Precisión de Entrenamiento: 0.8831\n",
      "Iteración 17176 - Lote 280/352 - Pérdida de Entrenamiento: 0.3422, Precisión de Entrenamiento: 0.8826\n",
      "Iteración 17211 - Lote 315/352 - Pérdida de Entrenamiento: 0.3433, Precisión de Entrenamiento: 0.8823\n",
      "Iteración 17246 - Lote 350/352 - Pérdida de Entrenamiento: 0.3446, Precisión de Entrenamiento: 0.8817\n",
      "Tiempo de la época 49: 86.64 segundos\n",
      "Val loss: 0.3917, Val acc: 0.8730\n",
      "0.0004\n",
      "Epoch 50/70\n",
      "Iteración 17283 - Lote 35/352 - Pérdida de Entrenamiento: 0.3398, Precisión de Entrenamiento: 0.8792\n",
      "Iteración 17318 - Lote 70/352 - Pérdida de Entrenamiento: 0.3392, Precisión de Entrenamiento: 0.8854\n",
      "Iteración 17353 - Lote 105/352 - Pérdida de Entrenamiento: 0.3311, Precisión de Entrenamiento: 0.8871\n",
      "Iteración 17388 - Lote 140/352 - Pérdida de Entrenamiento: 0.3291, Precisión de Entrenamiento: 0.8866\n",
      "Iteración 17423 - Lote 175/352 - Pérdida de Entrenamiento: 0.3332, Precisión de Entrenamiento: 0.8849\n",
      "Iteración 17458 - Lote 210/352 - Pérdida de Entrenamiento: 0.3304, Precisión de Entrenamiento: 0.8865\n",
      "Iteración 17493 - Lote 245/352 - Pérdida de Entrenamiento: 0.3316, Precisión de Entrenamiento: 0.8857\n",
      "Iteración 17528 - Lote 280/352 - Pérdida de Entrenamiento: 0.3305, Precisión de Entrenamiento: 0.8854\n",
      "Iteración 17563 - Lote 315/352 - Pérdida de Entrenamiento: 0.3291, Precisión de Entrenamiento: 0.8866\n",
      "Iteración 17598 - Lote 350/352 - Pérdida de Entrenamiento: 0.3285, Precisión de Entrenamiento: 0.8867\n",
      "Tiempo de la época 50: 86.27 segundos\n",
      "Val loss: 0.3857, Val acc: 0.8740\n",
      "Checkpoint guardado en CheckpointsResNet110_SD\\best_checkpoint_epoch_50.pth\n",
      "Checkpoint del mejor modelo guardado en la época 50\n",
      "0.0004\n",
      "Epoch 51/70\n",
      "Iteración 17635 - Lote 35/352 - Pérdida de Entrenamiento: 0.3308, Precisión de Entrenamiento: 0.8859\n",
      "Iteración 17670 - Lote 70/352 - Pérdida de Entrenamiento: 0.3415, Precisión de Entrenamiento: 0.8807\n",
      "Iteración 17705 - Lote 105/352 - Pérdida de Entrenamiento: 0.3412, Precisión de Entrenamiento: 0.8795\n",
      "Iteración 17740 - Lote 140/352 - Pérdida de Entrenamiento: 0.3426, Precisión de Entrenamiento: 0.8798\n",
      "Iteración 17775 - Lote 175/352 - Pérdida de Entrenamiento: 0.3363, Precisión de Entrenamiento: 0.8831\n",
      "Iteración 17810 - Lote 210/352 - Pérdida de Entrenamiento: 0.3373, Precisión de Entrenamiento: 0.8830\n",
      "Iteración 17845 - Lote 245/352 - Pérdida de Entrenamiento: 0.3352, Precisión de Entrenamiento: 0.8835\n",
      "Iteración 17880 - Lote 280/352 - Pérdida de Entrenamiento: 0.3344, Precisión de Entrenamiento: 0.8836\n",
      "Iteración 17915 - Lote 315/352 - Pérdida de Entrenamiento: 0.3342, Precisión de Entrenamiento: 0.8840\n",
      "Iteración 17950 - Lote 350/352 - Pérdida de Entrenamiento: 0.3357, Precisión de Entrenamiento: 0.8832\n",
      "Tiempo de la época 51: 86.19 segundos\n",
      "Val loss: 0.3859, Val acc: 0.8762\n",
      "0.0004\n",
      "Epoch 52/70\n",
      "Iteración 17987 - Lote 35/352 - Pérdida de Entrenamiento: 0.3254, Precisión de Entrenamiento: 0.8902\n",
      "Iteración 18022 - Lote 70/352 - Pérdida de Entrenamiento: 0.3394, Precisión de Entrenamiento: 0.8812\n",
      "Iteración 18057 - Lote 105/352 - Pérdida de Entrenamiento: 0.3394, Precisión de Entrenamiento: 0.8830\n",
      "Iteración 18092 - Lote 140/352 - Pérdida de Entrenamiento: 0.3314, Precisión de Entrenamiento: 0.8873\n",
      "Iteración 18127 - Lote 175/352 - Pérdida de Entrenamiento: 0.3303, Precisión de Entrenamiento: 0.8875\n",
      "Iteración 18162 - Lote 210/352 - Pérdida de Entrenamiento: 0.3322, Precisión de Entrenamiento: 0.8858\n",
      "Iteración 18197 - Lote 245/352 - Pérdida de Entrenamiento: 0.3311, Precisión de Entrenamiento: 0.8861\n",
      "Iteración 18232 - Lote 280/352 - Pérdida de Entrenamiento: 0.3323, Precisión de Entrenamiento: 0.8855\n",
      "Iteración 18267 - Lote 315/352 - Pérdida de Entrenamiento: 0.3329, Precisión de Entrenamiento: 0.8850\n",
      "Iteración 18302 - Lote 350/352 - Pérdida de Entrenamiento: 0.3307, Precisión de Entrenamiento: 0.8857\n",
      "Tiempo de la época 52: 86.39 segundos\n",
      "Val loss: 0.3834, Val acc: 0.8748\n",
      "Checkpoint guardado en CheckpointsResNet110_SD\\best_checkpoint_epoch_52.pth\n",
      "Checkpoint del mejor modelo guardado en la época 52\n",
      "0.0004\n",
      "Epoch 53/70\n",
      "Iteración 18339 - Lote 35/352 - Pérdida de Entrenamiento: 0.3052, Precisión de Entrenamiento: 0.8962\n",
      "Iteración 18374 - Lote 70/352 - Pérdida de Entrenamiento: 0.3249, Precisión de Entrenamiento: 0.8895\n",
      "Iteración 18409 - Lote 105/352 - Pérdida de Entrenamiento: 0.3179, Precisión de Entrenamiento: 0.8911\n",
      "Iteración 18444 - Lote 140/352 - Pérdida de Entrenamiento: 0.3193, Precisión de Entrenamiento: 0.8898\n",
      "Iteración 18479 - Lote 175/352 - Pérdida de Entrenamiento: 0.3209, Precisión de Entrenamiento: 0.8895\n",
      "Iteración 18514 - Lote 210/352 - Pérdida de Entrenamiento: 0.3223, Precisión de Entrenamiento: 0.8890\n",
      "Iteración 18549 - Lote 245/352 - Pérdida de Entrenamiento: 0.3227, Precisión de Entrenamiento: 0.8893\n",
      "Iteración 18584 - Lote 280/352 - Pérdida de Entrenamiento: 0.3248, Precisión de Entrenamiento: 0.8884\n",
      "Iteración 18619 - Lote 315/352 - Pérdida de Entrenamiento: 0.3226, Precisión de Entrenamiento: 0.8889\n",
      "Iteración 18654 - Lote 350/352 - Pérdida de Entrenamiento: 0.3227, Precisión de Entrenamiento: 0.8882\n",
      "Tiempo de la época 53: 86.51 segundos\n",
      "Val loss: 0.3886, Val acc: 0.8716\n",
      "0.0004\n",
      "Epoch 54/70\n",
      "Iteración 18691 - Lote 35/352 - Pérdida de Entrenamiento: 0.3124, Precisión de Entrenamiento: 0.8915\n",
      "Iteración 18726 - Lote 70/352 - Pérdida de Entrenamiento: 0.3137, Precisión de Entrenamiento: 0.8902\n",
      "Iteración 18761 - Lote 105/352 - Pérdida de Entrenamiento: 0.3191, Precisión de Entrenamiento: 0.8897\n",
      "Iteración 18796 - Lote 140/352 - Pérdida de Entrenamiento: 0.3192, Precisión de Entrenamiento: 0.8882\n",
      "Iteración 18831 - Lote 175/352 - Pérdida de Entrenamiento: 0.3156, Precisión de Entrenamiento: 0.8903\n",
      "Iteración 18866 - Lote 210/352 - Pérdida de Entrenamiento: 0.3199, Precisión de Entrenamiento: 0.8890\n",
      "Iteración 18901 - Lote 245/352 - Pérdida de Entrenamiento: 0.3218, Precisión de Entrenamiento: 0.8888\n",
      "Iteración 18936 - Lote 280/352 - Pérdida de Entrenamiento: 0.3221, Precisión de Entrenamiento: 0.8890\n",
      "Iteración 18971 - Lote 315/352 - Pérdida de Entrenamiento: 0.3232, Precisión de Entrenamiento: 0.8889\n",
      "Iteración 19006 - Lote 350/352 - Pérdida de Entrenamiento: 0.3250, Precisión de Entrenamiento: 0.8883\n",
      "Tiempo de la época 54: 86.88 segundos\n",
      "Val loss: 0.3810, Val acc: 0.8766\n",
      "Checkpoint guardado en CheckpointsResNet110_SD\\best_checkpoint_epoch_54.pth\n",
      "Checkpoint del mejor modelo guardado en la época 54\n",
      "0.0004\n",
      "Epoch 55/70\n",
      "Iteración 19043 - Lote 35/352 - Pérdida de Entrenamiento: 0.3246, Precisión de Entrenamiento: 0.8924\n",
      "Iteración 19078 - Lote 70/352 - Pérdida de Entrenamiento: 0.3194, Precisión de Entrenamiento: 0.8933\n",
      "Iteración 19113 - Lote 105/352 - Pérdida de Entrenamiento: 0.3216, Precisión de Entrenamiento: 0.8897\n",
      "Iteración 19148 - Lote 140/352 - Pérdida de Entrenamiento: 0.3206, Precisión de Entrenamiento: 0.8889\n",
      "Iteración 19183 - Lote 175/352 - Pérdida de Entrenamiento: 0.3216, Precisión de Entrenamiento: 0.8884\n",
      "Iteración 19218 - Lote 210/352 - Pérdida de Entrenamiento: 0.3222, Precisión de Entrenamiento: 0.8879\n",
      "Iteración 19253 - Lote 245/352 - Pérdida de Entrenamiento: 0.3214, Precisión de Entrenamiento: 0.8883\n",
      "Iteración 19288 - Lote 280/352 - Pérdida de Entrenamiento: 0.3193, Precisión de Entrenamiento: 0.8892\n",
      "Iteración 19323 - Lote 315/352 - Pérdida de Entrenamiento: 0.3197, Precisión de Entrenamiento: 0.8893\n",
      "Iteración 19358 - Lote 350/352 - Pérdida de Entrenamiento: 0.3211, Precisión de Entrenamiento: 0.8888\n",
      "Tiempo de la época 55: 86.58 segundos\n",
      "Val loss: 0.3772, Val acc: 0.8768\n",
      "Checkpoint guardado en CheckpointsResNet110_SD\\best_checkpoint_epoch_55.pth\n",
      "Checkpoint del mejor modelo guardado en la época 55\n",
      "0.0004\n",
      "Epoch 56/70\n",
      "Iteración 19395 - Lote 35/352 - Pérdida de Entrenamiento: 0.3287, Precisión de Entrenamiento: 0.8875\n",
      "Iteración 19430 - Lote 70/352 - Pérdida de Entrenamiento: 0.3244, Precisión de Entrenamiento: 0.8884\n",
      "Iteración 19465 - Lote 105/352 - Pérdida de Entrenamiento: 0.3269, Precisión de Entrenamiento: 0.8864\n",
      "Iteración 19500 - Lote 140/352 - Pérdida de Entrenamiento: 0.3312, Precisión de Entrenamiento: 0.8849\n",
      "Iteración 19535 - Lote 175/352 - Pérdida de Entrenamiento: 0.3314, Precisión de Entrenamiento: 0.8851\n",
      "Iteración 19570 - Lote 210/352 - Pérdida de Entrenamiento: 0.3308, Precisión de Entrenamiento: 0.8865\n",
      "Iteración 19605 - Lote 245/352 - Pérdida de Entrenamiento: 0.3310, Precisión de Entrenamiento: 0.8865\n",
      "Iteración 19640 - Lote 280/352 - Pérdida de Entrenamiento: 0.3312, Precisión de Entrenamiento: 0.8861\n",
      "Iteración 19675 - Lote 315/352 - Pérdida de Entrenamiento: 0.3289, Precisión de Entrenamiento: 0.8872\n",
      "Iteración 19710 - Lote 350/352 - Pérdida de Entrenamiento: 0.3275, Precisión de Entrenamiento: 0.8870\n",
      "Tiempo de la época 56: 86.78 segundos\n",
      "Val loss: 0.3814, Val acc: 0.8766\n",
      "0.0004\n",
      "Epoch 57/70\n",
      "Iteración 19747 - Lote 35/352 - Pérdida de Entrenamiento: 0.3319, Precisión de Entrenamiento: 0.8821\n",
      "Iteración 19782 - Lote 70/352 - Pérdida de Entrenamiento: 0.3359, Precisión de Entrenamiento: 0.8849\n",
      "Iteración 19817 - Lote 105/352 - Pérdida de Entrenamiento: 0.3343, Precisión de Entrenamiento: 0.8868\n",
      "Iteración 19852 - Lote 140/352 - Pérdida de Entrenamiento: 0.3213, Precisión de Entrenamiento: 0.8908\n",
      "Iteración 19887 - Lote 175/352 - Pérdida de Entrenamiento: 0.3235, Precisión de Entrenamiento: 0.8897\n",
      "Iteración 19922 - Lote 210/352 - Pérdida de Entrenamiento: 0.3252, Precisión de Entrenamiento: 0.8894\n",
      "Iteración 19957 - Lote 245/352 - Pérdida de Entrenamiento: 0.3205, Precisión de Entrenamiento: 0.8910\n",
      "Iteración 19992 - Lote 280/352 - Pérdida de Entrenamiento: 0.3226, Precisión de Entrenamiento: 0.8901\n",
      "Iteración 20027 - Lote 315/352 - Pérdida de Entrenamiento: 0.3228, Precisión de Entrenamiento: 0.8900\n",
      "Iteración 20062 - Lote 350/352 - Pérdida de Entrenamiento: 0.3243, Precisión de Entrenamiento: 0.8892\n",
      "Tiempo de la época 57: 86.61 segundos\n",
      "Val loss: 0.3809, Val acc: 0.8740\n",
      "0.0004\n",
      "Epoch 58/70\n",
      "Iteración 20099 - Lote 35/352 - Pérdida de Entrenamiento: 0.3091, Precisión de Entrenamiento: 0.8944\n",
      "Iteración 20134 - Lote 70/352 - Pérdida de Entrenamiento: 0.3225, Precisión de Entrenamiento: 0.8915\n",
      "Iteración 20169 - Lote 105/352 - Pérdida de Entrenamiento: 0.3209, Precisión de Entrenamiento: 0.8896\n",
      "Iteración 20204 - Lote 140/352 - Pérdida de Entrenamiento: 0.3229, Precisión de Entrenamiento: 0.8890\n",
      "Iteración 20239 - Lote 175/352 - Pérdida de Entrenamiento: 0.3278, Precisión de Entrenamiento: 0.8873\n",
      "Iteración 20274 - Lote 210/352 - Pérdida de Entrenamiento: 0.3240, Precisión de Entrenamiento: 0.8892\n",
      "Iteración 20309 - Lote 245/352 - Pérdida de Entrenamiento: 0.3271, Precisión de Entrenamiento: 0.8872\n",
      "Iteración 20344 - Lote 280/352 - Pérdida de Entrenamiento: 0.3245, Precisión de Entrenamiento: 0.8879\n",
      "Iteración 20379 - Lote 315/352 - Pérdida de Entrenamiento: 0.3245, Precisión de Entrenamiento: 0.8878\n",
      "Iteración 20414 - Lote 350/352 - Pérdida de Entrenamiento: 0.3236, Precisión de Entrenamiento: 0.8878\n",
      "Tiempo de la época 58: 86.82 segundos\n",
      "Val loss: 0.3850, Val acc: 0.8746\n",
      "0.0004\n",
      "Epoch 59/70\n",
      "Iteración 20451 - Lote 35/352 - Pérdida de Entrenamiento: 0.3170, Precisión de Entrenamiento: 0.8946\n",
      "Iteración 20486 - Lote 70/352 - Pérdida de Entrenamiento: 0.3179, Precisión de Entrenamiento: 0.8905\n",
      "Iteración 20521 - Lote 105/352 - Pérdida de Entrenamiento: 0.3142, Precisión de Entrenamiento: 0.8918\n",
      "Iteración 20556 - Lote 140/352 - Pérdida de Entrenamiento: 0.3134, Precisión de Entrenamiento: 0.8914\n",
      "Iteración 20591 - Lote 175/352 - Pérdida de Entrenamiento: 0.3143, Precisión de Entrenamiento: 0.8917\n",
      "Iteración 20626 - Lote 210/352 - Pérdida de Entrenamiento: 0.3178, Precisión de Entrenamiento: 0.8898\n",
      "Iteración 20661 - Lote 245/352 - Pérdida de Entrenamiento: 0.3216, Precisión de Entrenamiento: 0.8879\n",
      "Iteración 20696 - Lote 280/352 - Pérdida de Entrenamiento: 0.3238, Precisión de Entrenamiento: 0.8872\n",
      "Iteración 20731 - Lote 315/352 - Pérdida de Entrenamiento: 0.3250, Precisión de Entrenamiento: 0.8870\n",
      "Iteración 20766 - Lote 350/352 - Pérdida de Entrenamiento: 0.3245, Precisión de Entrenamiento: 0.8867\n",
      "Tiempo de la época 59: 86.29 segundos\n",
      "Val loss: 0.3871, Val acc: 0.8748\n",
      "4e-05\n",
      "Epoch 60/70\n",
      "Iteración 20803 - Lote 35/352 - Pérdida de Entrenamiento: 0.3095, Precisión de Entrenamiento: 0.8940\n",
      "Iteración 20838 - Lote 70/352 - Pérdida de Entrenamiento: 0.3073, Precisión de Entrenamiento: 0.8953\n",
      "Iteración 20873 - Lote 105/352 - Pérdida de Entrenamiento: 0.3110, Precisión de Entrenamiento: 0.8929\n",
      "Iteración 20908 - Lote 140/352 - Pérdida de Entrenamiento: 0.3168, Precisión de Entrenamiento: 0.8908\n",
      "Iteración 20943 - Lote 175/352 - Pérdida de Entrenamiento: 0.3165, Precisión de Entrenamiento: 0.8900\n",
      "Iteración 20978 - Lote 210/352 - Pérdida de Entrenamiento: 0.3183, Precisión de Entrenamiento: 0.8895\n",
      "Iteración 21013 - Lote 245/352 - Pérdida de Entrenamiento: 0.3200, Precisión de Entrenamiento: 0.8897\n",
      "Iteración 21048 - Lote 280/352 - Pérdida de Entrenamiento: 0.3203, Precisión de Entrenamiento: 0.8893\n",
      "Iteración 21083 - Lote 315/352 - Pérdida de Entrenamiento: 0.3224, Precisión de Entrenamiento: 0.8892\n",
      "Iteración 21118 - Lote 350/352 - Pérdida de Entrenamiento: 0.3232, Precisión de Entrenamiento: 0.8887\n",
      "Tiempo de la época 60: 86.78 segundos\n",
      "Val loss: 0.3806, Val acc: 0.8742\n",
      "4e-05\n",
      "Epoch 61/70\n",
      "Iteración 21155 - Lote 35/352 - Pérdida de Entrenamiento: 0.3139, Precisión de Entrenamiento: 0.8933\n",
      "Iteración 21190 - Lote 70/352 - Pérdida de Entrenamiento: 0.3258, Precisión de Entrenamiento: 0.8865\n",
      "Iteración 21225 - Lote 105/352 - Pérdida de Entrenamiento: 0.3258, Precisión de Entrenamiento: 0.8844\n",
      "Iteración 21260 - Lote 140/352 - Pérdida de Entrenamiento: 0.3276, Precisión de Entrenamiento: 0.8837\n",
      "Iteración 21295 - Lote 175/352 - Pérdida de Entrenamiento: 0.3261, Precisión de Entrenamiento: 0.8843\n",
      "Iteración 21330 - Lote 210/352 - Pérdida de Entrenamiento: 0.3250, Precisión de Entrenamiento: 0.8847\n",
      "Iteración 21365 - Lote 245/352 - Pérdida de Entrenamiento: 0.3238, Precisión de Entrenamiento: 0.8854\n",
      "Iteración 21400 - Lote 280/352 - Pérdida de Entrenamiento: 0.3261, Precisión de Entrenamiento: 0.8851\n",
      "Iteración 21435 - Lote 315/352 - Pérdida de Entrenamiento: 0.3255, Precisión de Entrenamiento: 0.8855\n",
      "Iteración 21470 - Lote 350/352 - Pérdida de Entrenamiento: 0.3268, Precisión de Entrenamiento: 0.8852\n",
      "Tiempo de la época 61: 86.79 segundos\n",
      "Val loss: 0.3804, Val acc: 0.8756\n",
      "4e-05\n",
      "Epoch 62/70\n",
      "Iteración 21507 - Lote 35/352 - Pérdida de Entrenamiento: 0.3242, Precisión de Entrenamiento: 0.8888\n",
      "Iteración 21542 - Lote 70/352 - Pérdida de Entrenamiento: 0.3179, Precisión de Entrenamiento: 0.8897\n",
      "Iteración 21577 - Lote 105/352 - Pérdida de Entrenamiento: 0.3176, Precisión de Entrenamiento: 0.8886\n",
      "Iteración 21612 - Lote 140/352 - Pérdida de Entrenamiento: 0.3153, Precisión de Entrenamiento: 0.8891\n",
      "Iteración 21647 - Lote 175/352 - Pérdida de Entrenamiento: 0.3171, Precisión de Entrenamiento: 0.8875\n",
      "Iteración 21682 - Lote 210/352 - Pérdida de Entrenamiento: 0.3203, Precisión de Entrenamiento: 0.8874\n",
      "Iteración 21717 - Lote 245/352 - Pérdida de Entrenamiento: 0.3221, Precisión de Entrenamiento: 0.8865\n",
      "Iteración 21752 - Lote 280/352 - Pérdida de Entrenamiento: 0.3246, Precisión de Entrenamiento: 0.8857\n",
      "Iteración 21787 - Lote 315/352 - Pérdida de Entrenamiento: 0.3245, Precisión de Entrenamiento: 0.8860\n",
      "Iteración 21822 - Lote 350/352 - Pérdida de Entrenamiento: 0.3235, Precisión de Entrenamiento: 0.8869\n",
      "Tiempo de la época 62: 86.23 segundos\n",
      "Val loss: 0.3820, Val acc: 0.8742\n",
      "4e-05\n",
      "Epoch 63/70\n",
      "Iteración 21859 - Lote 35/352 - Pérdida de Entrenamiento: 0.3377, Precisión de Entrenamiento: 0.8835\n",
      "Iteración 21894 - Lote 70/352 - Pérdida de Entrenamiento: 0.3282, Precisión de Entrenamiento: 0.8847\n",
      "Iteración 21929 - Lote 105/352 - Pérdida de Entrenamiento: 0.3274, Precisión de Entrenamiento: 0.8844\n",
      "Iteración 21964 - Lote 140/352 - Pérdida de Entrenamiento: 0.3230, Precisión de Entrenamiento: 0.8876\n",
      "Iteración 21999 - Lote 175/352 - Pérdida de Entrenamiento: 0.3260, Precisión de Entrenamiento: 0.8877\n",
      "Iteración 22034 - Lote 210/352 - Pérdida de Entrenamiento: 0.3254, Precisión de Entrenamiento: 0.8879\n",
      "Iteración 22069 - Lote 245/352 - Pérdida de Entrenamiento: 0.3237, Precisión de Entrenamiento: 0.8887\n",
      "Iteración 22104 - Lote 280/352 - Pérdida de Entrenamiento: 0.3260, Precisión de Entrenamiento: 0.8879\n",
      "Iteración 22139 - Lote 315/352 - Pérdida de Entrenamiento: 0.3263, Precisión de Entrenamiento: 0.8879\n",
      "Iteración 22174 - Lote 350/352 - Pérdida de Entrenamiento: 0.3250, Precisión de Entrenamiento: 0.8882\n",
      "Tiempo de la época 63: 86.61 segundos\n",
      "Val loss: 0.3848, Val acc: 0.8724\n",
      "4.000000000000001e-06\n",
      "Epoch 64/70\n",
      "Iteración 22211 - Lote 35/352 - Pérdida de Entrenamiento: 0.3323, Precisión de Entrenamiento: 0.8864\n",
      "Iteración 22246 - Lote 70/352 - Pérdida de Entrenamiento: 0.3294, Precisión de Entrenamiento: 0.8869\n",
      "Iteración 22281 - Lote 105/352 - Pérdida de Entrenamiento: 0.3218, Precisión de Entrenamiento: 0.8880\n",
      "Iteración 22316 - Lote 140/352 - Pérdida de Entrenamiento: 0.3178, Precisión de Entrenamiento: 0.8895\n",
      "Iteración 22351 - Lote 175/352 - Pérdida de Entrenamiento: 0.3173, Precisión de Entrenamiento: 0.8900\n",
      "Iteración 22386 - Lote 210/352 - Pérdida de Entrenamiento: 0.3169, Precisión de Entrenamiento: 0.8906\n",
      "Iteración 22421 - Lote 245/352 - Pérdida de Entrenamiento: 0.3156, Precisión de Entrenamiento: 0.8908\n",
      "Iteración 22456 - Lote 280/352 - Pérdida de Entrenamiento: 0.3177, Precisión de Entrenamiento: 0.8893\n",
      "Iteración 22491 - Lote 315/352 - Pérdida de Entrenamiento: 0.3188, Precisión de Entrenamiento: 0.8889\n",
      "Iteración 22526 - Lote 350/352 - Pérdida de Entrenamiento: 0.3180, Precisión de Entrenamiento: 0.8892\n",
      "Tiempo de la época 64: 86.84 segundos\n",
      "Val loss: 0.3820, Val acc: 0.8754\n",
      "4.000000000000001e-06\n",
      "Epoch 65/70\n",
      "Iteración 22563 - Lote 35/352 - Pérdida de Entrenamiento: 0.3292, Precisión de Entrenamiento: 0.8844\n",
      "Iteración 22598 - Lote 70/352 - Pérdida de Entrenamiento: 0.3343, Precisión de Entrenamiento: 0.8809\n",
      "Iteración 22633 - Lote 105/352 - Pérdida de Entrenamiento: 0.3260, Precisión de Entrenamiento: 0.8837\n",
      "Iteración 22668 - Lote 140/352 - Pérdida de Entrenamiento: 0.3287, Precisión de Entrenamiento: 0.8839\n",
      "Iteración 22703 - Lote 175/352 - Pérdida de Entrenamiento: 0.3288, Precisión de Entrenamiento: 0.8837\n",
      "Iteración 22738 - Lote 210/352 - Pérdida de Entrenamiento: 0.3272, Precisión de Entrenamiento: 0.8846\n",
      "Iteración 22773 - Lote 245/352 - Pérdida de Entrenamiento: 0.3264, Precisión de Entrenamiento: 0.8852\n",
      "Iteración 22808 - Lote 280/352 - Pérdida de Entrenamiento: 0.3243, Precisión de Entrenamiento: 0.8867\n",
      "Iteración 22843 - Lote 315/352 - Pérdida de Entrenamiento: 0.3243, Precisión de Entrenamiento: 0.8865\n",
      "Iteración 22878 - Lote 350/352 - Pérdida de Entrenamiento: 0.3236, Precisión de Entrenamiento: 0.8869\n",
      "Tiempo de la época 65: 86.53 segundos\n",
      "Val loss: 0.3784, Val acc: 0.8740\n",
      "4.000000000000001e-06\n",
      "Epoch 66/70\n",
      "Iteración 22915 - Lote 35/352 - Pérdida de Entrenamiento: 0.3476, Precisión de Entrenamiento: 0.8810\n",
      "Iteración 22950 - Lote 70/352 - Pérdida de Entrenamiento: 0.3426, Precisión de Entrenamiento: 0.8804\n",
      "Iteración 22985 - Lote 105/352 - Pérdida de Entrenamiento: 0.3342, Precisión de Entrenamiento: 0.8824\n",
      "Iteración 23020 - Lote 140/352 - Pérdida de Entrenamiento: 0.3270, Precisión de Entrenamiento: 0.8866\n",
      "Iteración 23055 - Lote 175/352 - Pérdida de Entrenamiento: 0.3271, Precisión de Entrenamiento: 0.8858\n",
      "Iteración 23090 - Lote 210/352 - Pérdida de Entrenamiento: 0.3242, Precisión de Entrenamiento: 0.8869\n",
      "Iteración 23125 - Lote 245/352 - Pérdida de Entrenamiento: 0.3238, Precisión de Entrenamiento: 0.8871\n",
      "Iteración 23160 - Lote 280/352 - Pérdida de Entrenamiento: 0.3224, Precisión de Entrenamiento: 0.8876\n",
      "Iteración 23195 - Lote 315/352 - Pérdida de Entrenamiento: 0.3226, Precisión de Entrenamiento: 0.8869\n",
      "Iteración 23230 - Lote 350/352 - Pérdida de Entrenamiento: 0.3226, Precisión de Entrenamiento: 0.8870\n",
      "Tiempo de la época 66: 86.51 segundos\n",
      "Val loss: 0.3947, Val acc: 0.8720\n",
      "4.000000000000001e-06\n",
      "Epoch 67/70\n",
      "Iteración 23267 - Lote 35/352 - Pérdida de Entrenamiento: 0.3286, Precisión de Entrenamiento: 0.8846\n",
      "Iteración 23302 - Lote 70/352 - Pérdida de Entrenamiento: 0.3312, Precisión de Entrenamiento: 0.8817\n",
      "Iteración 23337 - Lote 105/352 - Pérdida de Entrenamiento: 0.3232, Precisión de Entrenamiento: 0.8856\n",
      "Iteración 23372 - Lote 140/352 - Pérdida de Entrenamiento: 0.3300, Precisión de Entrenamiento: 0.8832\n",
      "Iteración 23407 - Lote 175/352 - Pérdida de Entrenamiento: 0.3284, Precisión de Entrenamiento: 0.8853\n",
      "Iteración 23442 - Lote 210/352 - Pérdida de Entrenamiento: 0.3290, Precisión de Entrenamiento: 0.8853\n",
      "Iteración 23477 - Lote 245/352 - Pérdida de Entrenamiento: 0.3275, Precisión de Entrenamiento: 0.8861\n",
      "Iteración 23512 - Lote 280/352 - Pérdida de Entrenamiento: 0.3247, Precisión de Entrenamiento: 0.8877\n",
      "Iteración 23547 - Lote 315/352 - Pérdida de Entrenamiento: 0.3229, Precisión de Entrenamiento: 0.8880\n",
      "Iteración 23582 - Lote 350/352 - Pérdida de Entrenamiento: 0.3243, Precisión de Entrenamiento: 0.8873\n",
      "Tiempo de la época 67: 86.55 segundos\n",
      "Val loss: 0.3821, Val acc: 0.8758\n",
      "4.000000000000001e-07\n",
      "Epoch 68/70\n",
      "Iteración 23619 - Lote 35/352 - Pérdida de Entrenamiento: 0.3168, Precisión de Entrenamiento: 0.8868\n",
      "Iteración 23654 - Lote 70/352 - Pérdida de Entrenamiento: 0.3157, Precisión de Entrenamiento: 0.8894\n",
      "Iteración 23689 - Lote 105/352 - Pérdida de Entrenamiento: 0.3137, Precisión de Entrenamiento: 0.8901\n",
      "Iteración 23724 - Lote 140/352 - Pérdida de Entrenamiento: 0.3126, Precisión de Entrenamiento: 0.8902\n",
      "Iteración 23759 - Lote 175/352 - Pérdida de Entrenamiento: 0.3128, Precisión de Entrenamiento: 0.8900\n",
      "Iteración 23794 - Lote 210/352 - Pérdida de Entrenamiento: 0.3117, Precisión de Entrenamiento: 0.8909\n",
      "Iteración 23829 - Lote 245/352 - Pérdida de Entrenamiento: 0.3143, Precisión de Entrenamiento: 0.8907\n",
      "Iteración 23864 - Lote 280/352 - Pérdida de Entrenamiento: 0.3143, Precisión de Entrenamiento: 0.8909\n",
      "Iteración 23899 - Lote 315/352 - Pérdida de Entrenamiento: 0.3162, Precisión de Entrenamiento: 0.8906\n",
      "Iteración 23934 - Lote 350/352 - Pérdida de Entrenamiento: 0.3173, Precisión de Entrenamiento: 0.8903\n",
      "Tiempo de la época 68: 86.68 segundos\n",
      "Val loss: 0.3835, Val acc: 0.8766\n",
      "4.000000000000001e-07\n",
      "Epoch 69/70\n",
      "Iteración 23971 - Lote 35/352 - Pérdida de Entrenamiento: 0.3408, Precisión de Entrenamiento: 0.8855\n",
      "Iteración 24006 - Lote 70/352 - Pérdida de Entrenamiento: 0.3431, Precisión de Entrenamiento: 0.8827\n",
      "Iteración 24041 - Lote 105/352 - Pérdida de Entrenamiento: 0.3332, Precisión de Entrenamiento: 0.8871\n",
      "Iteración 24076 - Lote 140/352 - Pérdida de Entrenamiento: 0.3363, Precisión de Entrenamiento: 0.8846\n",
      "Iteración 24111 - Lote 175/352 - Pérdida de Entrenamiento: 0.3343, Precisión de Entrenamiento: 0.8846\n",
      "Iteración 24146 - Lote 210/352 - Pérdida de Entrenamiento: 0.3317, Precisión de Entrenamiento: 0.8860\n",
      "Iteración 24181 - Lote 245/352 - Pérdida de Entrenamiento: 0.3283, Precisión de Entrenamiento: 0.8870\n",
      "Iteración 24216 - Lote 280/352 - Pérdida de Entrenamiento: 0.3237, Precisión de Entrenamiento: 0.8881\n",
      "Iteración 24251 - Lote 315/352 - Pérdida de Entrenamiento: 0.3237, Precisión de Entrenamiento: 0.8878\n",
      "Iteración 24286 - Lote 350/352 - Pérdida de Entrenamiento: 0.3217, Precisión de Entrenamiento: 0.8887\n",
      "Tiempo de la época 69: 86.71 segundos\n",
      "Val loss: 0.3793, Val acc: 0.8752\n",
      "4.000000000000001e-07\n",
      "Epoch 70/70\n",
      "Iteración 24323 - Lote 35/352 - Pérdida de Entrenamiento: 0.3260, Precisión de Entrenamiento: 0.8812\n",
      "Iteración 24358 - Lote 70/352 - Pérdida de Entrenamiento: 0.3202, Precisión de Entrenamiento: 0.8888\n",
      "Iteración 24393 - Lote 105/352 - Pérdida de Entrenamiento: 0.3247, Precisión de Entrenamiento: 0.8862\n",
      "Iteración 24428 - Lote 140/352 - Pérdida de Entrenamiento: 0.3279, Precisión de Entrenamiento: 0.8854\n",
      "Iteración 24463 - Lote 175/352 - Pérdida de Entrenamiento: 0.3239, Precisión de Entrenamiento: 0.8873\n",
      "Iteración 24498 - Lote 210/352 - Pérdida de Entrenamiento: 0.3206, Precisión de Entrenamiento: 0.8880\n",
      "Iteración 24533 - Lote 245/352 - Pérdida de Entrenamiento: 0.3224, Precisión de Entrenamiento: 0.8879\n",
      "Iteración 24568 - Lote 280/352 - Pérdida de Entrenamiento: 0.3219, Precisión de Entrenamiento: 0.8884\n",
      "Iteración 24603 - Lote 315/352 - Pérdida de Entrenamiento: 0.3217, Precisión de Entrenamiento: 0.8891\n",
      "Iteración 24638 - Lote 350/352 - Pérdida de Entrenamiento: 0.3213, Precisión de Entrenamiento: 0.8888\n",
      "Tiempo de la época 70: 86.51 segundos\n",
      "Val loss: 0.3812, Val acc: 0.8760\n",
      "Early stopping at epoch 70\n",
      "\n",
      "Tiempo total de entrenamiento: 6372.85 segundos\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1300x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Configuraciones\n",
    "use_gpu = torch.cuda.is_available()\n",
    "\n",
    "# Directorio para guardar checkpoints (opcional)\n",
    "checkpoint_dir = \"CheckpointsResNet110_SD\"\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "feature_maps = {}\n",
    "if __name__ == \"__main__\":\n",
    "    # Hiperparámetros\n",
    "    batch_size = 128\n",
    "    epochs = 70\n",
    "    max_iterations = 600000  # Ajusta según sea necesario\n",
    "    learning_rate = 0.04\n",
    "    n_evaluations_per_epoch = 10\n",
    "    data_augmentation = True\n",
    "    weight_decay = 1e-4\n",
    "    early_stop_thresh = 15\n",
    "    patience = 3\n",
    "    survival_prob = 0.5  # Probabilidad de supervivencia para la profundidad estocástica\n",
    "\n",
    "    # Inicializar el modelo con profundidad estocástica\n",
    "    model = resnet110_SD(survival_prob=0.5)\n",
    "\n",
    "    # Definir función de pérdida\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Entrenar el modelo\n",
    "    curves = train_model(\n",
    "        model=model,\n",
    "        train_dataset=train_cifar10,\n",
    "        val_dataset=val_cifar10,\n",
    "        epochs=epochs,\n",
    "        max_iterations=max_iterations,\n",
    "        criterion=criterion,\n",
    "        batch_size=batch_size,\n",
    "        lr=learning_rate,\n",
    "        n_evaluations_per_epoch=n_evaluations_per_epoch,\n",
    "        early_stop_thresh=early_stop_thresh,\n",
    "        show_gradients=show_gradients_ResNet_110,\n",
    "        patience=patience,\n",
    "        use_gpu=use_gpu,\n",
    "        data_augmentation=data_augmentation,\n",
    "        resume_checkpoint=None,  # Establece a una cadena de caracteres para reanudar, por ejemplo, \"best_checkpoint_epoch_10.pth\"\n",
    "        weight_decay=weight_decay\n",
    "    )\n",
    "\n",
    "    # Plotear curvas de entrenamiento\n",
    "    show_curves(curves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor modelo encontrado: best_checkpoint_epoch_55.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ricar\\AppData\\Local\\Temp\\ipykernel_23696\\2590339615.py:37: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión TOP1 en el conjunto de prueba: 87.21%\n",
      "Precisión TOP5 en el conjunto de prueba: 99.54%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Definir el directorio donde se guardaron los checkpoints\n",
    "checkpoint_dir = \"CheckpointsResNet110_SD\"\n",
    "\n",
    "# Obtener la lista de archivos de checkpoint\n",
    "checkpoint_files = os.listdir(checkpoint_dir)\n",
    "checkpoint_files = [f for f in checkpoint_files if f.startswith('best_checkpoint_epoch_') and f.endswith('.pth')]\n",
    "\n",
    "# Encontrar el checkpoint con el número de época más alto (el mejor modelo)\n",
    "epochs_in_checkpoints = []\n",
    "for f in checkpoint_files:\n",
    "    epoch_str = f.replace('best_checkpoint_epoch_', '').replace('.pth', '')\n",
    "    try:\n",
    "        epoch_num = int(epoch_str)\n",
    "        epochs_in_checkpoints.append((epoch_num, f))\n",
    "    except ValueError:\n",
    "        continue\n",
    "\n",
    "if epochs_in_checkpoints:\n",
    "    best_epoch, best_checkpoint_file = max(epochs_in_checkpoints)\n",
    "    checkpoint_path = os.path.join(checkpoint_dir, best_checkpoint_file)\n",
    "    print(f\"Mejor modelo encontrado: {best_checkpoint_file}\")\n",
    "else:\n",
    "    print(\"No se encontraron archivos de checkpoint\")\n",
    "    raise FileNotFoundError(\"No se encontraron archivos de checkpoint.\")\n",
    "\n",
    "# Crear una instancia del modelo ResNet\n",
    "model = resnet110_SD(survival_prob=0.5)  # Asegúrate de usar la misma configuración que en el entrenamiento\n",
    "\n",
    "# Configurar el dispositivo (CPU o GPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Cargar el checkpoint\n",
    "checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.to(device)\n",
    "\n",
    "# Crear el DataLoader para el conjunto de prueba\n",
    "test_loader = DataLoader(\n",
    "    test_cifar10,\n",
    "    batch_size=128,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=torch.cuda.is_available()\n",
    ")\n",
    "\n",
    "# Definir la función para evaluar TOP1 y TOP5\n",
    "def evaluate_topk(loader, model, device, k=(1, 5)):\n",
    "    model.eval()\n",
    "    topk_accs = [0] * len(k)\n",
    "    data_count = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, pred = outputs.topk(max(k), dim=1, largest=True, sorted=True)\n",
    "            pred = pred.t()\n",
    "            correct = pred.eq(labels.view(1, -1).expand_as(pred))\n",
    "            for i, kk in enumerate(k):\n",
    "                correct_k = correct[:kk].reshape(-1).float().sum(0, keepdim=True)\n",
    "                topk_accs[i] += correct_k.item()\n",
    "            data_count += labels.size(0)\n",
    "    topk_accs = [acc / data_count for acc in topk_accs]\n",
    "    return topk_accs\n",
    "\n",
    "# Evaluar el modelo en el conjunto de prueba\n",
    "top1_acc, top5_acc = evaluate_topk(test_loader, model, device, k=(1, 5))\n",
    "\n",
    "print(f\"Precisión TOP1 en el conjunto de prueba: {top1_acc * 100:.2f}%\")\n",
    "print(f\"Precisión TOP5 en el conjunto de prueba: {top5_acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rqPkjiLhAw0f",
    "outputId": "75787e44-c3b4-46cf-c099-aeef2832936b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet110_SD\n",
      "Total number of params 1727962\n",
      "Total layers 110\n",
      "\n"
     ]
    }
   ],
   "source": [
    "__all__ = ['ResNet', 'resnet110_SD']\n",
    "\n",
    "def test(net):\n",
    "    total_params = 0\n",
    "\n",
    "    for x in filter(lambda p: p.requires_grad, net.parameters()):\n",
    "        total_params += np.prod(x.data.numpy().shape)\n",
    "    print(\"Total number of params\", total_params)\n",
    "    print(\"Total layers\", len(list(filter(lambda p: p.requires_grad and len(p.data.size())>1, net.parameters()))))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    for net_name in __all__:\n",
    "        if net_name.startswith('resnet'):\n",
    "            print(net_name)\n",
    "            test(globals()[net_name]())\n",
    "            print()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "EL4106",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
